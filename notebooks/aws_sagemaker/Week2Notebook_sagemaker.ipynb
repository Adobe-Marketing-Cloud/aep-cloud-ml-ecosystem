{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a71779b-7434-4c0f-8034-5dd6155819e5",
   "metadata": {},
   "source": [
    "# Scope of Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d6f83",
   "metadata": {},
   "source": [
    "The goal of this notebook is to showcase how you can prepare data for the future goal of consumption by an ML model, and leveraging functionality in the Adobe Experience Platform to generate features at scale and make it available in your choice of cloud storage.\n",
    "\n",
    "![Workflow](../media/CMLE-SageMaker-Notebooks-Week2-Workflow.png)\n",
    "\n",
    "We'll go through several steps:\n",
    "- **Creating a query** to encapsulate what a good featurized dataset will be.\n",
    "- **Executing that query** and storing the results.\n",
    "- **Setting up a flow** to export the results into cloud storage.\n",
    "- **Executing that flow** to deliver the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c97ed",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c4d19",
   "metadata": {},
   "source": [
    "This notebook requires some configuration data to properly authenticate to your Adobe Experience Platform instance. You should be able to find all the values required above by following the Setup section of the **README**.\n",
    "\n",
    "The next cell will be looking for your configuration file under your **ADOBE_HOME** path to fetch the values used throughout this notebook. See more details in the Setup section of the **README** to understand how to create your configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6591794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "\n",
    "os.environ[\"ADOBE_HOME\"] = \"../../\"\n",
    "if \"ADOBE_HOME\" not in os.environ:\n",
    "    raise Exception(\"ADOBE_HOME environment variable needs to be set.\")\n",
    "\n",
    "config = ConfigParser()\n",
    "config_path = os.path.join(os.environ[\"ADOBE_HOME\"], \"conf\", config_file)\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    raise Exception(f\"Looking for configuration under {config_path} but config not found, please verify path\")\n",
    "\n",
    "config.read(config_path)\n",
    "\n",
    "ims_org_id = config.get(\"Platform\", \"ims_org_id\")\n",
    "sandbox_name = config.get(\"Platform\", \"sandbox_name\")\n",
    "environment = config.get(\"Platform\", \"environment\")\n",
    "client_id = config.get(\"Authentication\", \"client_id\")\n",
    "client_secret = config.get(\"Authentication\", \"client_secret\")\n",
    "scopes = config.get(\"Authentication\", \"scopes\")\n",
    "tech_account_id = config.get(\"Authentication\", \"tech_acct_id\")\n",
    "dataset_id = config.get(\"Platform\", \"dataset_id\")\n",
    "if not dataset_id:\n",
    "    raise Exception(\"Looking for dataset_id saved in week1 notebook to continue the exploration in week2 notebook but not found\")\n",
    "export_path = config.get(\"Cloud\", \"export_path\")\n",
    "data_format = config.get(\"Cloud\", \"data_format\")\n",
    "compression_type = config.get(\"Cloud\", \"compression_type\")\n",
    "\n",
    "s3_bucket_name = config.get(\"AWS\",\"s3_bucket_name\")\n",
    "s3_prefix = config.get(\"AWS\",\"s3_prefix\")\n",
    "cfn_stack_id = config.get(\"AWS\", \"cfn_stack_id\")\n",
    "\n",
    "if not s3_bucket_name or not s3_prefix or not cfn_stack_id:\n",
    "    raise Exception(\"Please make sure the above fields s3_bucket_name, s3_prefix, cfn_stack_id are all populated with valid values in config.ini under the AWS section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c11ff7",
   "metadata": {},
   "source": [
    "Some utility functions that will be used throughout this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d67a6-60ce-491f-9459-fa66b62a9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "NOTEBOOK_METADATA_FILE=\"/opt/ml/metadata/resource-metadata.json\"\n",
    "if os.path.exists(NOTEBOOK_METADATA_FILE):\n",
    "    with open(NOTEBOOK_METADATA_FILE,\"rb\") as f:\n",
    "        username = json.loads(f.read())['UserProfileName']\n",
    "print(f\"Username: {username}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b3d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ui_link(tenant_id, resource_type, resource_id):\n",
    "    if environment == \"prod\":\n",
    "        prefix = f\"https://experience.adobe.com\"\n",
    "    else:\n",
    "        prefix = f\"https://experience-{environment}.adobe.com\"\n",
    "    return f\"{prefix}/#/@{tenant_id}/sname:{sandbox_name}/platform/{resource_type}/{resource_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda86eb",
   "metadata": {},
   "source": [
    "Before we run anything, make sure to install the following required libraries for this notebook. They are all publicly available libraries and the latest version should work fine.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "    \n",
    "If you are not using `pip` to manage Python packages, or that you use a variation like `pip3`, please update the cell below accordingly to install these packages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf128411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aepp in /usr/local/lib/python3.10/site-packages (0.2.7)\n",
      "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/site-packages (from aepp) (2.6.0)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/site-packages (from aepp) (1.0.1)\n",
      "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.10/site-packages (from aepp) (2.3.7.post1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from aepp) (2.28.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from aepp) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/site-packages (from pandas->aepp) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->aepp) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas->aepp) (2.8.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from pathlib2->aepp) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/site-packages (from PyJWT->aepp) (39.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->aepp) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->aepp) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->aepp) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->aepp) (1.26.14)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=3.4.0->PyJWT->aepp) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.4.0->PyJWT->aepp) (2.21)\n",
      "Requirement already satisfied: pygresql in /usr/local/lib/python3.10/site-packages (5.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install aepp\n",
    "!pip install pygresql==5.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de58f29",
   "metadata": {},
   "source": [
    "We'll be using the [aepp Python library](https://github.com/pitchmuc/aepp) here to interact with AEP APIs and create a schema and dataset suitable for adding our synthetic data further down the line. This library simply provides a programmatic interface around the REST APIs, but all these steps could be completed similarly using the raw APIs directly or even in the UI. For more information on the underlying APIs please see [the API reference guide](https://developer.adobe.com/experience-platform-apis/).\n",
    "\n",
    "Before any calls can take place, we need to configure the library and setup authentication credentials. For this you'll need the following piece of information. For information about how you can get these, please refer to the `Setup` section of the **README**:\n",
    "- Client ID\n",
    "- Client secret\n",
    "- Private key\n",
    "- Technical account ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527b93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aepp\n",
    "\n",
    "aepp.configure(\n",
    "  org_id=ims_org_id,\n",
    "  tech_id=tech_account_id, \n",
    "  secret=client_secret,\n",
    "  scopes=scopes,\n",
    "  client_id=client_id,\n",
    "  sandbox=sandbox_name,\n",
    "  environment=environment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3ae6c",
   "metadata": {},
   "source": [
    "# 1. Creating Featurization Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc91620",
   "metadata": {},
   "source": [
    "In the previous week we created some synthetic data under a dataset in your Adobe Experience Platform instance, and now we're ready to use it to generate features that can then be fed to our ML model. For this purpose we'll be using the [Query Service](https://experienceleague.adobe.com/docs/experience-platform/query/home.html?lang=en#) which lets us access data from any dataset and run queries at scale. The end goal here is to compress this dataset into a small subset of meaningful features that will be relevant to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f67fe0",
   "metadata": {},
   "source": [
    "Before we can issue queries, we need to find the table name corresponding to our dataset. Please make sure your dataset ID was entered in your configuration as part of the setup, it should be available under the `dataset_id` variable in this notebook.\n",
    "\n",
    "Every dataset in AEP should have a corresponding table in PQS based on its name. We can use AEP APIs to get that information with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48136f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmle_week1_new_notebook_with_ecid_used_dataset_created_by_saikat'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aepp import catalog\n",
    "\n",
    "cat_conn = catalog.Catalog()\n",
    "\n",
    "dataset_info = cat_conn.getDataSet(dataset_id)\n",
    "table_name = dataset_info[dataset_id][\"tags\"][\"adobe/pqs/table\"][0]\n",
    "table_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46a9a3",
   "metadata": {},
   "source": [
    "And because some of the data we created in the previous week is under a custom field group, we need to fetch your tenant ID since the data will be nested under it. This can be accomplished simply with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86179fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aamds'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aepp import schema\n",
    "\n",
    "schema_conn = schema.Schema()\n",
    "\n",
    "tenant_id = schema_conn.getTenantId()\n",
    "tenant_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504ec24",
   "metadata": {},
   "source": [
    "Now we can use that table to query it via Query Service. Every query is able to run at scale leveraging Spark-based distributed computing power in the backend, so the goal is to take this large dataset, extract meaningful features and only keep a smaller subset to feed into a ML model.\n",
    "\n",
    "We'll be leveraging `aepp` again to interact with Query Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645d030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepp import queryservice\n",
    "\n",
    "qs = queryservice.QueryService()\n",
    "qs_conn = qs.connection()\n",
    "qs_conn['dbname']=f'{sandbox_name}:{table_name}'\n",
    "qs_cursor = queryservice.InteractiveQuery(qs_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a37cbf7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> If at any point in this notebook the connection to Query Service is closed, you can refresh it by re-enabling that cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e2589",
   "metadata": {},
   "source": [
    "Let's first define our ML problem scientifically:\n",
    "- **What kind of problem** are we solving? We'd like to predict whether someone is likely to subscribe or not. We treat that as a binary classification problem, you are either subscribed or you are not.\n",
    "- What is our **target variable**? Whether a subscription occurred or not for a given user.\n",
    "- What are our **positive labels**? People who have at least 1 event corresponding to a subscription (marked as `web.formFilledOut`). We will keep a single feature row from the event where they actually subscribed.\n",
    "- What are our **negative labels**? People who don't have a single event corresponding to a subscription. We will keep a random row to avoid having bias in the data.\n",
    "\n",
    "Let's put that into practice and start looking at our positive labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf7db90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive classes: 15030\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventType</th>\n",
       "      <th>userId</th>\n",
       "      <th>subscriptionOccurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01054714817856066632264746967668888198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01108987448326166452882902459550847869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01234932524049684301600430771576676651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01242509742845154266705851412711275265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01370262440242301894771514187123049829</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eventType                                  userId  \\\n",
       "0  web.formFilledOut  01054714817856066632264746967668888198   \n",
       "1  web.formFilledOut  01108987448326166452882902459550847869   \n",
       "2  web.formFilledOut  01234932524049684301600430771576676651   \n",
       "3  web.formFilledOut  01242509742845154266705851412711275265   \n",
       "4  web.formFilledOut  01370262440242301894771514187123049829   \n",
       "\n",
       "   subscriptionOccurred  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_positive_labels = f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT\n",
    "        eventType,\n",
    "        _{tenant_id}.cmle_id as userId,\n",
    "        SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "            OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "            AS \"subscriptionOccurred\"\n",
    "    FROM {table_name}\n",
    ")\n",
    "WHERE subscriptionOccurred = 1 AND eventType = 'web.formFilledOut'\n",
    "\"\"\"\n",
    "\n",
    "df_positive_labels = qs_cursor.query(query_positive_labels, output=\"dataframe\")\n",
    "print(f\"Number of positive classes: {len(df_positive_labels)}\")\n",
    "df_positive_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091826e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "    \n",
    "We are using a sub-query because we want to filter on the `subscriptionOccurred` which is defined as part of the query, so it can't be used in a filter condition unless it is in a sub-query.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f39fa9",
   "metadata": {},
   "source": [
    "Now let's look at our negative labels. Because we just want to retain a random row to avoid bias, we need to introduce randomness into our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44bd2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative classes: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>subscriptionOccurred</th>\n",
       "      <th>random_row_number_for_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01027994177972439148069092698714414382</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01066367784525869370502097766291450913</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01117296890525140996735553609305695042</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01149554820363915324573708359099551093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01172121447143590196349410086995740317</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   userId  subscriptionOccurred  \\\n",
       "0  01027994177972439148069092698714414382                     0   \n",
       "1  01066367784525869370502097766291450913                     0   \n",
       "2  01117296890525140996735553609305695042                     0   \n",
       "3  01149554820363915324573708359099551093                     0   \n",
       "4  01172121447143590196349410086995740317                     0   \n",
       "\n",
       "   random_row_number_for_user  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           1  \n",
       "4                           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_negative_labels = f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT\n",
    "        _{tenant_id}.cmle_id as userId,\n",
    "        SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "            OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "            AS \"subscriptionOccurred\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    ")\n",
    "WHERE subscriptionOccurred = 0 AND random_row_number_for_user = 1\n",
    "\"\"\"\n",
    "\n",
    "df_negative_labels = qs_cursor.query(query_negative_labels, output=\"dataframe\")\n",
    "print(f\"Number of negative classes: {len(df_negative_labels)}\")\n",
    "df_negative_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c285f",
   "metadata": {},
   "source": [
    "Putting it all together, we can query both our positive and negative classes with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944198a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventType</th>\n",
       "      <th>userId</th>\n",
       "      <th>subscriptionOccurred</th>\n",
       "      <th>random_row_number_for_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commerce.productViews</td>\n",
       "      <td>01027994177972439148069092698714414382</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01054714817856066632264746967668888198</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>01108987448326166452882902459550847869</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>01117296890525140996735553609305695042</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>directMarketing.emailOpened</td>\n",
       "      <td>01149554820363915324573708359099551093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     eventType                                  userId  \\\n",
       "0        commerce.productViews  01027994177972439148069092698714414382   \n",
       "1            web.formFilledOut  01054714817856066632264746967668888198   \n",
       "2            web.formFilledOut  01108987448326166452882902459550847869   \n",
       "3    directMarketing.emailSent  01117296890525140996735553609305695042   \n",
       "4  directMarketing.emailOpened  01149554820363915324573708359099551093   \n",
       "\n",
       "   subscriptionOccurred  random_row_number_for_user  \n",
       "0                     0                           1  \n",
       "1                     1                           5  \n",
       "2                     1                           1  \n",
       "3                     0                           1  \n",
       "4                     0                           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels = f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT\n",
    "        eventType,\n",
    "        _{tenant_id}.cmle_id as userId,\n",
    "        SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "            OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "            AS \"subscriptionOccurred\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "\"\"\"\n",
    "\n",
    "df_labels = qs_cursor.query(query_labels, output=\"dataframe\")\n",
    "print(f\"Number of classes: {len(df_labels)}\")\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ebdb7",
   "metadata": {},
   "source": [
    "Now let's think what kind of features make sense for this kind of problem that we would like to eventually feed to an ML model. There's 2 main kinds of features we're interested in:\n",
    "- **Actionable features**: different actions the user actually took in response to a marketing event.\n",
    "- **Temporal features**: distribution over time of the actions the user took. This is useful for modeling to capture behavior over time and not just statically at any particular point in time.\n",
    "\n",
    "We can think of a few simple things that can be derived from this data for the actionable features:\n",
    "- **Number of emails** that were sent for marketing purposes and received by the user.\n",
    "- Portion of these emails that were actually **opened**.\n",
    "- Portion of these emails where the user actually **clicked** on the link.\n",
    "- **Number of products** that were viewed.\n",
    "- Number of **propositions that were interacted with**.\n",
    "- Number of **propositions that were dismissed**.\n",
    "- Number of **links that were clicked on**.\n",
    "\n",
    "Regarding the temporal features, we can look at consecutive occurrences between various events. This can be accomplished using the `TIME_BETWEEN_PREVIOUS_MATCH` function. So we take the previous actionable features and look at their temporal distribution:\n",
    "- Number of minutes between 2 consecutive emails received.\n",
    "- Number of minutes between 2 consecutive emails opened.\n",
    "- Number of minutes between 2 consecutive emails where the user actually clicked on the link.\n",
    "- Number of minutes between 2 consecutive product views.\n",
    "- Number of minutes between 2 propositions that were interacted with.\n",
    "- Number of minutes between 2 propositions that were dismissed.\n",
    "- Number of minutes between 2 links that were clicked on.\n",
    "\n",
    "Let's put all that in practice and look how we can create these features inside a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97e2ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>emailsReceived</th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>emailsClicked</th>\n",
       "      <th>productsViewed</th>\n",
       "      <th>propositionInteracts</th>\n",
       "      <th>propositionDismissed</th>\n",
       "      <th>webLinkClicks</th>\n",
       "      <th>minutes_since_emailSent</th>\n",
       "      <th>minutes_since_emailOpened</th>\n",
       "      <th>minutes_since_emailClick</th>\n",
       "      <th>minutes_since_productView</th>\n",
       "      <th>minutes_since_propositionInteract</th>\n",
       "      <th>minutes_since_propositionDismiss</th>\n",
       "      <th>minutes_since_linkClick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01046464403641925015932682550398209571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01046464403641925015932682550398209571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01046464403641925015932682550398209571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01046464403641925015932682550398209571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01046464403641925015932682550398209571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   userId  emailsReceived  emailsOpened  \\\n",
       "0  01046464403641925015932682550398209571               0             0   \n",
       "1  01046464403641925015932682550398209571               0             0   \n",
       "2  01046464403641925015932682550398209571               0             0   \n",
       "3  01046464403641925015932682550398209571               0             0   \n",
       "4  01046464403641925015932682550398209571               0             0   \n",
       "\n",
       "   emailsClicked  productsViewed  propositionInteracts  propositionDismissed  \\\n",
       "0              0               0                     0                     0   \n",
       "1              0               0                     0                     0   \n",
       "2              0               0                     0                     0   \n",
       "3              0               0                     0                     0   \n",
       "4              0               0                     0                     0   \n",
       "\n",
       "   webLinkClicks  minutes_since_emailSent  minutes_since_emailOpened  \\\n",
       "0              0                      NaN                        NaN   \n",
       "1              0                      NaN                        NaN   \n",
       "2              0                      NaN                        NaN   \n",
       "3              1                      NaN                        NaN   \n",
       "4              1                      NaN                        NaN   \n",
       "\n",
       "   minutes_since_emailClick  minutes_since_productView  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "   minutes_since_propositionInteract minutes_since_propositionDismiss  \\\n",
       "0                                NaN                             None   \n",
       "1                                NaN                             None   \n",
       "2                                NaN                             None   \n",
       "3                                NaN                             None   \n",
       "4                                NaN                             None   \n",
       "\n",
       "   minutes_since_linkClick  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      0.0  \n",
       "4                      1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_features = f\"\"\"\n",
    "SELECT\n",
    "    _{tenant_id}.cmle_id as userId,\n",
    "    SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"emailsReceived\",\n",
    "    SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"emailsOpened\",       \n",
    "    SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"emailsClicked\",       \n",
    "    SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"productsViewed\",       \n",
    "    SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"propositionInteracts\",       \n",
    "    SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"propositionDismissed\",\n",
    "    SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"webLinkClicks\" ,\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_emailSent\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_emailOpened\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_emailClick\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_productView\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_propositionInteract\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_propositionDismiss\",\n",
    "    TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "       OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "       AS \"minutes_since_linkClick\"\n",
    "FROM {table_name}\n",
    "\"\"\"\n",
    "\n",
    "df_features = qs_cursor.query(query_features, output=\"dataframe\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2468b",
   "metadata": {},
   "source": [
    "At that point we have defined all our features, and we also have our classes cleanly defined, so we can tie everything together in a final query that will represent our training set to be used later on on our ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb182816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>eventType</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subscriptionOccurred</th>\n",
       "      <th>emailsReceived</th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>emailsClicked</th>\n",
       "      <th>productsViewed</th>\n",
       "      <th>propositionInteracts</th>\n",
       "      <th>propositionDismissed</th>\n",
       "      <th>webLinkClicks</th>\n",
       "      <th>minutes_since_emailSent</th>\n",
       "      <th>minutes_since_emailOpened</th>\n",
       "      <th>minutes_since_emailClick</th>\n",
       "      <th>minutes_since_productView</th>\n",
       "      <th>minutes_since_propositionInteract</th>\n",
       "      <th>minutes_since_propositionDismiss</th>\n",
       "      <th>minutes_since_linkClick</th>\n",
       "      <th>random_row_number_for_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01024918979328021024268398155289293841</td>\n",
       "      <td>advertising.impressions</td>\n",
       "      <td>2023-01-11 11:01:28.844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01313428821394797049107854074567613407</td>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>2023-01-11 11:07:12.511</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02993793241626222851527839833265197633</td>\n",
       "      <td>web.formFilledOut</td>\n",
       "      <td>2023-01-11 15:36:21.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03284744679335392483733573117571851574</td>\n",
       "      <td>advertising.impressions</td>\n",
       "      <td>2023-01-11 19:53:50.963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03077253005436651532049293706745952081</td>\n",
       "      <td>directMarketing.emailOpened</td>\n",
       "      <td>2023-01-11 20:45:29.123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   userId                    eventType  \\\n",
       "0  01024918979328021024268398155289293841      advertising.impressions   \n",
       "1  01313428821394797049107854074567613407    directMarketing.emailSent   \n",
       "2  02993793241626222851527839833265197633            web.formFilledOut   \n",
       "3  03284744679335392483733573117571851574      advertising.impressions   \n",
       "4  03077253005436651532049293706745952081  directMarketing.emailOpened   \n",
       "\n",
       "                 timestamp  subscriptionOccurred  emailsReceived  \\\n",
       "0  2023-01-11 11:01:28.844                     0               0   \n",
       "1  2023-01-11 11:07:12.511                     0               1   \n",
       "2  2023-01-11 15:36:21.667                     1               0   \n",
       "3  2023-01-11 19:53:50.963                     0               0   \n",
       "4  2023-01-11 20:45:29.123                     0               1   \n",
       "\n",
       "   emailsOpened  emailsClicked  productsViewed  propositionInteracts  \\\n",
       "0             0              0               0                     0   \n",
       "1             0              0               0                     0   \n",
       "2             0              0               0                     1   \n",
       "3             0              0               0                     0   \n",
       "4             3              0               0                     0   \n",
       "\n",
       "   propositionDismissed  webLinkClicks  minutes_since_emailSent  \\\n",
       "0                     0              0                      NaN   \n",
       "1                     0              0                      0.0   \n",
       "2                     0              0                      NaN   \n",
       "3                     0              0                      NaN   \n",
       "4                     0              0                    829.0   \n",
       "\n",
       "   minutes_since_emailOpened  minutes_since_emailClick  \\\n",
       "0                        NaN                       NaN   \n",
       "1                        NaN                       NaN   \n",
       "2                        NaN                       NaN   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       NaN   \n",
       "\n",
       "   minutes_since_productView  minutes_since_propositionInteract  \\\n",
       "0                        NaN                                NaN   \n",
       "1                        NaN                                NaN   \n",
       "2                        NaN                                1.0   \n",
       "3                        NaN                                NaN   \n",
       "4                        NaN                                NaN   \n",
       "\n",
       "  minutes_since_propositionDismiss  minutes_since_linkClick  \\\n",
       "0                             None                      NaN   \n",
       "1                             None                      NaN   \n",
       "2                             None                      NaN   \n",
       "3                             None                      NaN   \n",
       "4                             None                      NaN   \n",
       "\n",
       "   random_row_number_for_user  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                          10  \n",
       "3                           1  \n",
       "4                           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_training_set = f\"\"\"\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name} LIMIT 1000\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "ORDER BY timestamp\n",
    "\"\"\"\n",
    "\n",
    "df_training_set = qs_cursor.query(query_training_set, output=\"dataframe\")\n",
    "df_training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830a850",
   "metadata": {},
   "source": [
    "# 2. Generating Features Incrementally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9109f",
   "metadata": {},
   "source": [
    "Now in a typical ML workload you'll want to use incremental data to feed to your model, or data between some specific dates. For that purpose we can use snapshot information that is tracked inside Query Service every time a new batch of data is ingested, using the `history_meta` metadata table. For example, you can access the metadata for each batch of your dataset using the query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23cdd703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of snapshots/batches: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_generation</th>\n",
       "      <th>made_current_at</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>is_current_ancestor</th>\n",
       "      <th>is_current</th>\n",
       "      <th>output_record_count</th>\n",
       "      <th>output_byte_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-04 15:44:44.955</td>\n",
       "      <td>3825256663640337857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106317</td>\n",
       "      <td>14641809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-04 15:44:46.256</td>\n",
       "      <td>5250805769364495228</td>\n",
       "      <td>3.825257e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106736</td>\n",
       "      <td>14741300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-04 15:44:48.604</td>\n",
       "      <td>8316771932049439874</td>\n",
       "      <td>5.250806e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106059</td>\n",
       "      <td>14683324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-04 15:44:50.096</td>\n",
       "      <td>7241083319934178488</td>\n",
       "      <td>8.316772e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106474</td>\n",
       "      <td>14697877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-04 15:44:52.253</td>\n",
       "      <td>3157125847948566759</td>\n",
       "      <td>7.241083e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106675</td>\n",
       "      <td>14725877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-04 15:44:59.995</td>\n",
       "      <td>4460330323826197864</td>\n",
       "      <td>3.157126e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106716</td>\n",
       "      <td>14734401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2023-04-04 15:45:19.237</td>\n",
       "      <td>4818579672832050765</td>\n",
       "      <td>4.460330e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106525</td>\n",
       "      <td>14711442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2023-04-04 15:45:31.781</td>\n",
       "      <td>7870632534228575321</td>\n",
       "      <td>4.818580e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>106576</td>\n",
       "      <td>14750647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2023-04-04 15:45:43.676</td>\n",
       "      <td>1776236004746194930</td>\n",
       "      <td>7.870633e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>107138</td>\n",
       "      <td>14766853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2023-04-04 15:45:44.813</td>\n",
       "      <td>6433588580290892078</td>\n",
       "      <td>1.776236e+18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>107056</td>\n",
       "      <td>14779922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   snapshot_generation          made_current_at          snapshot_id  \\\n",
       "0                    0  2023-04-04 15:44:44.955  3825256663640337857   \n",
       "1                    1  2023-04-04 15:44:46.256  5250805769364495228   \n",
       "2                    2  2023-04-04 15:44:48.604  8316771932049439874   \n",
       "3                    3  2023-04-04 15:44:50.096  7241083319934178488   \n",
       "4                    4  2023-04-04 15:44:52.253  3157125847948566759   \n",
       "5                    5  2023-04-04 15:44:59.995  4460330323826197864   \n",
       "6                    6  2023-04-04 15:45:19.237  4818579672832050765   \n",
       "7                    7  2023-04-04 15:45:31.781  7870632534228575321   \n",
       "8                    8  2023-04-04 15:45:43.676  1776236004746194930   \n",
       "9                    9  2023-04-04 15:45:44.813  6433588580290892078   \n",
       "\n",
       "      parent_id  is_current_ancestor  is_current  output_record_count  \\\n",
       "0           NaN                 True       False               106317   \n",
       "1  3.825257e+18                 True       False               106736   \n",
       "2  5.250806e+18                 True       False               106059   \n",
       "3  8.316772e+18                 True       False               106474   \n",
       "4  7.241083e+18                 True       False               106675   \n",
       "5  3.157126e+18                 True       False               106716   \n",
       "6  4.460330e+18                 True       False               106525   \n",
       "7  4.818580e+18                 True       False               106576   \n",
       "8  7.870633e+18                 True       False               107138   \n",
       "9  1.776236e+18                 True        True               107056   \n",
       "\n",
       "   output_byte_size  \n",
       "0          14641809  \n",
       "1          14741300  \n",
       "2          14683324  \n",
       "3          14697877  \n",
       "4          14725877  \n",
       "5          14734401  \n",
       "6          14711442  \n",
       "7          14750647  \n",
       "8          14766853  \n",
       "9          14779922  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_meta = f\"\"\"\n",
    "SELECT * FROM (SELECT history_meta('{table_name}'))\n",
    "\"\"\"\n",
    "\n",
    "df_meta = qs_cursor.query(query_meta, output=\"dataframe\")\n",
    "print(f\"Total number of snapshots/batches: {len(df_meta)}\")\n",
    "df_meta.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49ae36b",
   "metadata": {},
   "source": [
    "Now let's use that information to transform our featurization query into an incremental version of it. We can use [anonymous blocks](https://experienceleague.adobe.com/docs/experience-platform/query/sql/syntax.html?lang=en#anonymous-block) to create variables used to filter on the snapshots. Anonymous blocks are useful to embed multiple queries at once and do things like defining variables and such. We can then use Query Service's `SNAPSHOT BETWEEN x AND y` functionality to query data incrementally.\n",
    "\n",
    "In our case because this is the first time generating the features we will look at data between the most recent snapshot and its preceding one (which should correspond to the last batch of data ingested), but this can be extended to query data between any snapshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5653c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n$$ BEGIN\\n\\nSET @from_snapshot_id = SELECT parent_id FROM (SELECT history_meta(\\'cmle_week1_new_notebook_with_ecid_used_dataset_created_by_saikat\\')) WHERE is_current = true;\\nSET @to_snapshot_id = SELECT snapshot_id FROM (SELECT history_meta(\\'cmle_week1_new_notebook_with_ecid_used_dataset_created_by_saikat\\')) WHERE is_current = true;\\n\\nSELECT *\\nFROM (\\n    SELECT _aamds.userid as userId, \\n       eventType,\\n       timestamp,\\n       SUM(CASE WHEN eventType=\\'web.formFilledOut\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid) \\n           AS \"subscriptionOccurred\",\\n       SUM(CASE WHEN eventType=\\'directMarketing.emailSent\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"emailsReceived\",\\n       SUM(CASE WHEN eventType=\\'directMarketing.emailOpened\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"emailsOpened\",       \\n       SUM(CASE WHEN eventType=\\'directMarketing.emailClicked\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"emailsClicked\",       \\n       SUM(CASE WHEN eventType=\\'commerce.productViews\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"productsViewed\",       \\n       SUM(CASE WHEN eventType=\\'decisioning.propositionInteract\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"propositionInteracts\",       \\n       SUM(CASE WHEN eventType=\\'decisioning.propositionDismiss\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"propositionDismissed\",\\n       SUM(CASE WHEN eventType=\\'web.webinteraction.linkClicks\\' THEN 1 ELSE 0 END) \\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"webLinkClicks\" ,\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'directMarketing.emailSent\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_emailSent\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'directMarketing.emailOpened\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_emailOpened\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'directMarketing.emailClicked\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_emailClick\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'commerce.productViews\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_productView\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'decisioning.propositionInteract\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_propositionInteract\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'propositionDismiss\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_propositionDismiss\",\\n       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = \\'web.webinteraction.linkClicks\\', \\'minutes\\')\\n           OVER (PARTITION BY _aamds.userid ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \\n           AS \"minutes_since_linkClick\",\\n        row_number() OVER (PARTITION BY _aamds.userid ORDER BY randn()) AS random_row_number_for_user\\n    FROM cmle_week1_new_notebook_with_ecid_used_dataset_created_by_saikat\\n    SNAPSHOT BETWEEN @from_snapshot_id AND @to_snapshot_id\\n)\\nWHERE (subscriptionOccurred = 1 AND eventType = \\'web.formFilledOut\\') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\\nORDER BY timestamp;\\n\\nEXCEPTION\\n  WHEN OTHER THEN\\n    SELECT \\'ERROR\\';\\n\\nEND $$;\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"\"\"\n",
    "$$ BEGIN\n",
    "\n",
    "SET @from_snapshot_id = SELECT parent_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "SET @to_snapshot_id = SELECT snapshot_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN @from_snapshot_id AND @to_snapshot_id\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "ORDER BY timestamp;\n",
    "\n",
    "EXCEPTION\n",
    "  WHEN OTHER THEN\n",
    "    SELECT 'ERROR';\n",
    "\n",
    "END $$;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e27b0",
   "metadata": {},
   "source": [
    "Note that we're not executing it interactively because this anonymous block is actually multiple queries chained together, and there is no simple way to return multiple result sets using PostgreSQL libraries.\n",
    "\n",
    "To solve that we can executed the query asynchronously and add a `CREATE TABLE x AS` statement at the beginning of our featurization query, to then look in that table. Note that because this is executed asynchronously, it goes into the Query Service scheduler and will take a few minutes to start executing, unlike the code we've been running until now which was synchronous and instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0521deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query started successfully and got assigned ID dc46636d-5c19-40f7-a772-524cc238a93e - it will take some time to execute\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "ctas_table_name = f\"cmle_example_training_set_incremental_{username}\"\n",
    "\n",
    "query_training_set_incremental = f\"\"\"\n",
    "$$ BEGIN\n",
    "\n",
    "SET @from_snapshot_id = SELECT parent_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "SET @to_snapshot_id = SELECT snapshot_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "\n",
    "CREATE TABLE {ctas_table_name} AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN @from_snapshot_id AND @to_snapshot_id LIMIT 1000\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "ORDER BY timestamp;\n",
    "\n",
    "EXCEPTION\n",
    "  WHEN OTHER THEN\n",
    "    SELECT 'ERROR';\n",
    "\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "query_incremental_res = qs.postQueries(\n",
    "    name=\"[CMLE][Week2] Query to generate incremental training data\",\n",
    "    sql=query_training_set_incremental,\n",
    "    dbname=f\"{sandbox_name}:{table_name}\"\n",
    ")\n",
    "query_incremental_id = query_incremental_res[\"id\"]\n",
    "print(f\"Query started successfully and got assigned ID {query_incremental_id} - it will take some time to execute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6c8493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_query_completion(query_id):\n",
    "    while True:\n",
    "        query_info = qs.getQuery(query_id)\n",
    "        query_state = query_info[\"state\"]\n",
    "        if query_state in [\"SUCCESS\", \"FAILED\"]:\n",
    "            break\n",
    "        print(\"Query is still in progress, sleeping...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "    duration_secs = query_info[\"elapsedTime\"] / 1000\n",
    "    if query_state == \"SUCCESS\":\n",
    "        print(f\"Query completed successfully in {duration_secs} seconds\")\n",
    "    else:\n",
    "        print(f\"Query failed with the following errors:\", file=sys.stderr)\n",
    "        for error in query_info[\"errors\"]:\n",
    "            print(f\"Error code {error['code']}: {error['message']}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "799152a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query completed successfully in 386.37 seconds\n"
     ]
    }
   ],
   "source": [
    "wait_for_query_completion(query_incremental_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e248ca",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> This should run in less than 10 minutes. If for whatever reason this does not finish in that time frame, it may get stuck creating the batch if the ingestion service is busy ingesting other data in your organization. We advise waiting longer or reaching out to your Adobe contact if this does not complete.\n",
    "    \n",
    "The same comment applies to subsequent cells where we use `wait_for_query_completion`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725608e3",
   "metadata": {},
   "source": [
    "This `CREATE TABLE x AS` statement actually does several steps:\n",
    "- It will create a brand **new dataset** in your Adobe Experience Platform organization and sandbox.\n",
    "- The **schema** for this dataset will be created ad-hoc to **match the fields** of our featurization query, so there is no need to manually create schemas and fieldgroups for this.\n",
    "\n",
    "You can verify that by going in the UI at the link below, and making sure it you see the dataset as shown in the screenshot further down. The number of records should correspond to the batch size you used in the previous week since we are querying a single snapshot/batch.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Re-executing the same query will fail, because it will try to create a table and not insert into it. We're solving this problem in the next section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14226fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset available as dataset ID 642d8e01ec08531c065b48b2 under https://experience.adobe.com/#/@aamds/sname:cmle/platform/dataset/browse/642d8e01ec08531c065b48b2\n"
     ]
    }
   ],
   "source": [
    "datasets_res = cat_conn.getDataSets(name=ctas_table_name)\n",
    "if len(datasets_res) != 1:\n",
    "    raise Exception(f\"Expected a single dataset but got {len(datasets_res)} ones\")\n",
    "ctas_dataset_id = list(datasets_res.keys())[0]\n",
    "ctas_dataset_link = get_ui_link(tenant_id, \"dataset/browse\", ctas_dataset_id)\n",
    "print(f\"Dataset available as dataset ID {ctas_dataset_id} under {ctas_dataset_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94dbbe",
   "metadata": {},
   "source": [
    "![CTAS](../media/CMLE-Notebooks-Week2-CTAS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff84519",
   "metadata": {},
   "source": [
    "Now we can just query it to see the structure of the data and verify it matches our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b5a5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>eventType</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subscriptionOccurred</th>\n",
       "      <th>emailsReceived</th>\n",
       "      <th>emailsOpened</th>\n",
       "      <th>emailsClicked</th>\n",
       "      <th>productsViewed</th>\n",
       "      <th>propositionInteracts</th>\n",
       "      <th>propositionDismissed</th>\n",
       "      <th>webLinkClicks</th>\n",
       "      <th>minutes_since_emailSent</th>\n",
       "      <th>minutes_since_emailOpened</th>\n",
       "      <th>minutes_since_emailClick</th>\n",
       "      <th>minutes_since_productView</th>\n",
       "      <th>minutes_since_propositionInteract</th>\n",
       "      <th>minutes_since_propositionDismiss</th>\n",
       "      <th>minutes_since_linkClick</th>\n",
       "      <th>random_row_number_for_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03496398227344712440123581041340192961</td>\n",
       "      <td>web.webpagedetails.pageViews</td>\n",
       "      <td>2023-01-10 14:44:38.161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01306047604382086256919152660635616402</td>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>2023-01-10 23:28:31.161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01899181931701313368403223253046030321</td>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>2023-01-12 09:54:47.161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03077253005436651532049293706745952081</td>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>2023-01-12 10:15:25.161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>809.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03622335536366276762200832126146857535</td>\n",
       "      <td>directMarketing.emailSent</td>\n",
       "      <td>2023-01-12 23:25:00.161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   userId                     eventType  \\\n",
       "0  03496398227344712440123581041340192961  web.webpagedetails.pageViews   \n",
       "1  01306047604382086256919152660635616402     directMarketing.emailSent   \n",
       "2  01899181931701313368403223253046030321     directMarketing.emailSent   \n",
       "3  03077253005436651532049293706745952081     directMarketing.emailSent   \n",
       "4  03622335536366276762200832126146857535     directMarketing.emailSent   \n",
       "\n",
       "                 timestamp  subscriptionOccurred  emailsReceived  \\\n",
       "0  2023-01-10 14:44:38.161                     0               0   \n",
       "1  2023-01-10 23:28:31.161                     0               1   \n",
       "2  2023-01-12 09:54:47.161                     0               1   \n",
       "3  2023-01-12 10:15:25.161                     0               2   \n",
       "4  2023-01-12 23:25:00.161                     0               1   \n",
       "\n",
       "   emailsOpened  emailsClicked  productsViewed  propositionInteracts  \\\n",
       "0             0              0               0                     0   \n",
       "1             0              0               0                     0   \n",
       "2             0              0               0                     0   \n",
       "3             3              0               0                     0   \n",
       "4             0              0               0                     0   \n",
       "\n",
       "   propositionDismissed  webLinkClicks  minutes_since_emailSent  \\\n",
       "0                     0              0                      NaN   \n",
       "1                     0              0                      0.0   \n",
       "2                     0              1                      0.0   \n",
       "3                     0              0                      0.0   \n",
       "4                     0              0                      0.0   \n",
       "\n",
       "   minutes_since_emailOpened minutes_since_emailClick  \\\n",
       "0                        NaN                     None   \n",
       "1                        NaN                     None   \n",
       "2                        NaN                     None   \n",
       "3                      809.0                     None   \n",
       "4                        NaN                     None   \n",
       "\n",
       "  minutes_since_productView minutes_since_propositionInteract  \\\n",
       "0                      None                              None   \n",
       "1                      None                              None   \n",
       "2                      None                              None   \n",
       "3                      None                              None   \n",
       "4                      None                              None   \n",
       "\n",
       "  minutes_since_propositionDismiss  minutes_since_linkClick  \\\n",
       "0                             None                      NaN   \n",
       "1                             None                      NaN   \n",
       "2                             None                    404.0   \n",
       "3                             None                      NaN   \n",
       "4                             None                      NaN   \n",
       "\n",
       "   random_row_number_for_user  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           1  \n",
       "4                           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ctas = f\"\"\"\n",
    "SELECT * FROM {ctas_table_name} LIMIT 10;\n",
    "\"\"\"\n",
    "qs = queryservice.QueryService()\n",
    "qs_conn = qs.connection()\n",
    "qs_conn['dbname']=f'{sandbox_name}:{ctas_table_name}'\n",
    "qs_cursor = queryservice.InteractiveQuery(qs_conn)\n",
    "df_ctas = qs_cursor.query(query_ctas, output=\"dataframe\")\n",
    "df_ctas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c11a9b",
   "metadata": {},
   "source": [
    "# 3. Templatizing the Featurization Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6f821",
   "metadata": {},
   "source": [
    "Now we've got a complete featurization query that can also be used to generate features incrementally, but we still want to go further:\n",
    "- The **snapshot window should be configurable** and easy to change without having to constantly create new queries.\n",
    "- The query itself should be **stored in a templatized way** so it can be referred to easily.\n",
    "- The query should be able to **create the table** automatically as well as **inserting into** a pre-existing table.\n",
    "\n",
    "Query Service has this concept of [templates](https://experienceleague.adobe.com/docs/experience-platform/query/ui/query-templates.html?lang=en) that we will be leveraging in this section to satisfy the requirements mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad387a",
   "metadata": {},
   "source": [
    "The first step is to make make sure we either create the table if it does not exist, otherwise insert into it. This can be done by checking if the table exists using the `table_exists` function and adding a condition in our anonymous block based on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bca2976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query started successfully and got assigned ID f7fd9bd5-cc7d-4984-b33a-f639cd48fd18 - it will take some time to execute\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query completed successfully in 202.07 seconds\n"
     ]
    }
   ],
   "source": [
    "query_training_set_ctas_or_insert = f\"\"\"\n",
    "$$ BEGIN\n",
    "\n",
    "SET @from_snapshot_id = SELECT parent_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "SET @to_snapshot_id = SELECT snapshot_id FROM (SELECT history_meta('{table_name}')) WHERE is_current = true;\n",
    "SET @my_table_exists = SELECT table_exists('{ctas_table_name}');\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS {ctas_table_name} AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN @from_snapshot_id AND @to_snapshot_id LIMIT 1000\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "ORDER BY timestamp;\n",
    "\n",
    "INSERT INTO {ctas_table_name}\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN @from_snapshot_id AND @to_snapshot_id LIMIT 1000\n",
    ")\n",
    "WHERE \n",
    "    @my_table_exists = 't' AND\n",
    "    ((subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1))\n",
    "ORDER BY timestamp;\n",
    "\n",
    "EXCEPTION\n",
    "  WHEN OTHER THEN\n",
    "    SELECT 'ERROR';\n",
    "\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "query_ctas_or_insert_res = qs.postQueries(\n",
    "    name=\"[CMLE][Week2] Query to generate training data as CTAS or Insert\",\n",
    "    sql=query_training_set_ctas_or_insert,\n",
    "    dbname=f\"{sandbox_name}:all\"\n",
    ")\n",
    "query_ctas_or_insert_id = query_ctas_or_insert_res[\"id\"]\n",
    "print(f\"Query started successfully and got assigned ID {query_ctas_or_insert_id} - it will take some time to execute\")\n",
    "\n",
    "wait_for_query_completion(query_ctas_or_insert_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996a390",
   "metadata": {},
   "source": [
    "The next step is to make the snapshot time window configurable. To do that we can replace the part containing the snapshot boundaries with variables as `$variable` so they can be passed at runtime using Query Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e2b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctas_table_name = f\"cmle_training_set_{username}\"\n",
    "\n",
    "query_training_set_template = f\"\"\"\n",
    "$$ BEGIN\n",
    "\n",
    "SET @my_table_exists = SELECT table_exists('{ctas_table_name}');\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS {ctas_table_name} AS\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN $from_snapshot_id AND $to_snapshot_id\n",
    ")\n",
    "WHERE (subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1)\n",
    "ORDER BY timestamp;\n",
    "\n",
    "INSERT INTO {ctas_table_name}\n",
    "SELECT *\n",
    "FROM (\n",
    "    SELECT _{tenant_id}.cmle_id as userId, \n",
    "       eventType,\n",
    "       timestamp,\n",
    "       SUM(CASE WHEN eventType='web.formFilledOut' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id) \n",
    "           AS \"subscriptionOccurred\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailSent' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsReceived\",\n",
    "       SUM(CASE WHEN eventType='directMarketing.emailOpened' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsOpened\",       \n",
    "       SUM(CASE WHEN eventType='directMarketing.emailClicked' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"emailsClicked\",       \n",
    "       SUM(CASE WHEN eventType='commerce.productViews' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"productsViewed\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionInteract' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionInteracts\",       \n",
    "       SUM(CASE WHEN eventType='decisioning.propositionDismiss' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"propositionDismissed\",\n",
    "       SUM(CASE WHEN eventType='web.webinteraction.linkClicks' THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"webLinkClicks\" ,\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailSent', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailSent\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailOpened', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailOpened\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'directMarketing.emailClicked', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_emailClick\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'commerce.productViews', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_productView\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'decisioning.propositionInteract', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionInteract\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'propositionDismiss', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_propositionDismiss\",\n",
    "       TIME_BETWEEN_PREVIOUS_MATCH(timestamp, eventType = 'web.webinteraction.linkClicks', 'minutes')\n",
    "           OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY timestamp ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) \n",
    "           AS \"minutes_since_linkClick\",\n",
    "        row_number() OVER (PARTITION BY _{tenant_id}.cmle_id ORDER BY randn()) AS random_row_number_for_user\n",
    "    FROM {table_name}\n",
    "    SNAPSHOT BETWEEN $from_snapshot_id AND $to_snapshot_id\n",
    ")\n",
    "WHERE \n",
    "    @my_table_exists = 't' AND\n",
    "    ((subscriptionOccurred = 1 AND eventType = 'web.formFilledOut') OR (subscriptionOccurred = 0 AND random_row_number_for_user = 1))\n",
    "ORDER BY timestamp;\n",
    "\n",
    "EXCEPTION\n",
    "  WHEN OTHER THEN\n",
    "    SELECT 'ERROR';\n",
    "\n",
    "END $$;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889495c2",
   "metadata": {},
   "source": [
    "We're not executing it because it has actual variables in it that will need to be resolved at runtime, so executing it right now would fail. We're ready to turn this into a proper template, which requires the following:\n",
    "- A **name** for your templatized query.\n",
    "- Some set of **query parameters** that you might want to already save - in our case we're not setting any so both snapshot boundaries can be set at runtie.\n",
    "- Your SQL **query**.\n",
    "\n",
    "Once you do this, the template should be available in the UI at the link below, as you can see in the screenshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48ae609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query template for training data created as ID f1d7db3a-adcb-472b-ac7d-c91b355b1182 under https://experience.adobe.com/#/@aamds/sname:cmle/platform/query/edit/f1d7db3a-adcb-472b-ac7d-c91b355b1182\n"
     ]
    }
   ],
   "source": [
    "template_res = qs.createQueryTemplate({\n",
    "  \"sql\": query_training_set_template,\n",
    "  \"queryParameters\": {},\n",
    "  \"name\": f\"[CMLE][Week2] Template for training data created by {username}\"\n",
    "})\n",
    "template_id = template_res[\"id\"]\n",
    "template_link = get_ui_link(tenant_id, \"query/edit\", template_id)\n",
    "\n",
    "print(f\"Query template for training data created as ID {template_id} under {template_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e33da",
   "metadata": {},
   "source": [
    "![Template](../media/CMLE-Notebooks-Week2-Template.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bb751",
   "metadata": {},
   "source": [
    "Now that the template is saved, we can refer to it at any time, and passing any kind of values for the snapshots that we want. So for example if you have streaming data coming through your system, you just need to find out the beginning snapshot ID and end snapshot ID, and you can execute this featurization query that will take care of querying between these 2 snapshots.\n",
    "\n",
    "In this example, we'll just query the entire dataset, so the very first and very last snapshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16b4303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query will go from start snapshot ID 3825256663640337857 to end snapshot ID 6433588580290892078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshot_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3825256663640337857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6433588580290892078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           snapshot_id\n",
       "0  3825256663640337857\n",
       "1  6433588580290892078"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_snapshots = f\"\"\"\n",
    "SELECT snapshot_id \n",
    "FROM (\n",
    "    SELECT history_meta('{table_name}')\n",
    ") \n",
    "WHERE is_current = true OR snapshot_generation = 0 \n",
    "ORDER BY snapshot_generation ASC\n",
    "\"\"\"\n",
    "\n",
    "df_snapshots = qs_cursor.query(query_snapshots, output=\"dataframe\")\n",
    "\n",
    "snapshot_start_id = str(df_snapshots[\"snapshot_id\"].iloc[0])\n",
    "snapshot_end_id = str(df_snapshots[\"snapshot_id\"].iloc[1])\n",
    "print(f\"Query will go from start snapshot ID {snapshot_start_id} to end snapshot ID {snapshot_end_id}\")\n",
    "\n",
    "df_snapshots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e650c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query started successfully and got assigned ID cf117097-703c-4851-957b-8d8571119248 - it will take some time to execute\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query is still in progress, sleeping...\n",
      "Query completed successfully in 284.399 seconds\n"
     ]
    }
   ],
   "source": [
    "query_final_res = qs.postQueries(\n",
    "    name=f\"[CMLE][Week2] Query to generate training data created by {username}\",\n",
    "    templateId=template_id,\n",
    "    queryParameters={\n",
    "        \"from_snapshot_id\": snapshot_start_id,\n",
    "        \"to_snapshot_id\": snapshot_end_id,\n",
    "    },\n",
    "    dbname=f\"{sandbox_name}:all\"\n",
    ")\n",
    "query_final_id = query_final_res[\"id\"]\n",
    "print(f\"Query started successfully and got assigned ID {query_final_id} - it will take some time to execute\")\n",
    "\n",
    "wait_for_query_completion(query_final_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53dcc26",
   "metadata": {},
   "source": [
    "At that point we got our full featurized dataset that is ready to plug into a ML model. But it's still in an Adobe Experience Platform dataset so far, and we need to bring it back to our cloud storage account outside of the Experience Platform to use our tool of choice, which will be covered in the next section.\n",
    "\n",
    "Before we go through that, we just need to find te dataset ID corresponding to the output of our templatized query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30cd28e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featurized data available in table cmle_training_set_cmenguy under dataset ID 642d912512f86b1c07ef5650 under https://experience.adobe.com/#/@aamds/sname:cmle/platform/dataset/browse/642d912512f86b1c07ef5650\n"
     ]
    }
   ],
   "source": [
    "ctas_table_info = cat_conn.getDataSets(name=ctas_table_name)\n",
    "created_dataset_id = list(ctas_table_info.keys())[0]\n",
    "created_dataset_link = get_ui_link(tenant_id,\"dataset/browse\",created_dataset_id)\n",
    "print(f\"Featurized data available in table {ctas_table_name} under dataset ID {created_dataset_id} under {created_dataset_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d255052",
   "metadata": {},
   "source": [
    "# 4. Exporting the Featurized Dataset to Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd86f26",
   "metadata": {},
   "source": [
    "Now that our featurized data is in a dataset, we need to bring it out to an external cloud storage filesystem from which the ML model training and scoring will be performed. \n",
    "\n",
    "For the purposes of this notebook we will be using the [Amazon S3](https://experienceleague.adobe.com/docs/experience-platform/destinations/catalog/cloud-storage/amazon-s3.html?lang=en#changelog) as the filesystem. Every Adobe Experience Platform has a S3 already setup as an [Amazon S3](https://aws.amazon.com/s3/) container. We'll be using that as a delivery mechanism for the featurized data, but this step can be customized to delivery this data to any cloud storage filesystem.\n",
    "\n",
    "To setup the delivery pipeline, we'll be using the [Flow Service for Destinations](https://developer.adobe.com/experience-platform-apis/references/destinations/) which will be responsible for picking up the featurized data and dump it into the S3. There's a few steps involved:\n",
    "- Creating a **source connection**.\n",
    "- Creating a **target connection**.\n",
    "- Creating a **data flow**.\n",
    "\n",
    "For that, again we use `aepp` to abstract all the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8587ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepp import flowservice\n",
    "\n",
    "flow_conn = flowservice.FlowService()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac5f2f",
   "metadata": {},
   "source": [
    "## 4.1 Creating the Source Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70633ae7",
   "metadata": {},
   "source": [
    "The source connection is responsible for connecting to your Adobe Experience Platform dataset so that the resulting flow will know exactly where to look for the data and in what format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da6602d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8858421d-1f92-4787-a140-caacd179ad9f'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_source_connection = {\n",
    "            \"name\": f\"[CMLE][Week2] Featurized Dataset S3 source connection created by {username}\",\n",
    "            \"data\": {\n",
    "                \"format\": \"parquet\"\n",
    "            },\n",
    "            \"connectionSpec\": {\n",
    "                \"id\": \"23598e46-f560-407b-88d5-ea6207e49db0\",\n",
    "                \"version\": \"1.0\"\n",
    "            },\n",
    "            \"params\": {\n",
    "                \"datasets\": [{\"dataSetId\": created_dataset_id}]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "source_res = flow_conn.createSourceConnection(\n",
    "    data = s3_source_connection\n",
    ")\n",
    "source_connection_id = source_res[\"id\"]\n",
    "source_connection_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104fed79",
   "metadata": {},
   "source": [
    "## 4.2 Creating the Base and Target Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909b3ee",
   "metadata": {},
   "source": [
    "The target connection is responsible for connecting to the destination filesystem. In our case, we want to connect to the DLZ and specify in what format the data will be stored, as well as the type of compression.\n",
    "\n",
    "Before we can create it however, we need to create a base connection to the Amazon S3. A base connection is just an instance of a connection spec that details how one authenticates to a particular destination. In our case, because we're using the S3 which is a known entity internal to Adobe, we can just reference the standard S3 connection spec ID and create an empty base connection.\n",
    "\n",
    "For reference, here is a list of all the connection specs available for the most popular cloud storage accounts (these IDs are global across every single customer account and sandbox):\n",
    "\n",
    "| Cloud Storage Type    | Connection Spec ID                   |\n",
    "|-----------------------|--------------------------------------|\n",
    "| Amazon S3             | 4fce964d-3f37-408f-9778-e597338a21ee |\n",
    "| Azure Blob Storage    | 6d6b59bf-fb58-4107-9064-4d246c0e5bb2 |\n",
    "| Azure Data Lake       | be2c3209-53bc-47e7-ab25-145db8b873e1 |\n",
    "| Data Landing Zone     | 10440537-2a7b-4583-ac39-ed38d4b848e8 |\n",
    "| Google Cloud Storage  | c5d93acb-ea8b-4b14-8f53-02138444ae99 |\n",
    "| SFTP                  | 36965a81-b1c6-401b-99f8-22508f1e6a26 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cccd44-605a-4bff-a23b-614fba7333f5",
   "metadata": {},
   "source": [
    "When creating the base connection, an auth attr expects a static set of AWS key/secret.This gets stored in a secrets service managed by Adobe. The CDK deployment created an IAMuser with an access key and secret key specifically for this base connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c270bf-c389-4ef6-8267-59b3a98ce650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ValidationError, ClientError\n",
    "cfn = boto3.client('cloudformation')\n",
    "secrets_manager = boto3.client('secretsmanager')\n",
    "try:\n",
    "    # validate cloudformation ID and get outputs\n",
    "    print('Validating CloudFormation ID')\n",
    "    response = cfn.describe_stacks(StackName=cfn_stack_id)\n",
    "    print('Stack found')\n",
    "    outputs = response['Stacks'][0]['Outputs']\n",
    "    for output in outputs:\n",
    "        if output['OutputKey'] == 'DataFlowUserAccessKey':\n",
    "            access_key = output['OutputValue']\n",
    "            print(f'Found access key: {access_key}')\n",
    "        if output['OutputKey'] == 'DataFlowUserSecretKey':\n",
    "            secret_name = output['OutputValue']\n",
    "            print(f'Found secret stored in Secrets Manager: {secret_name}')\n",
    "except ValidationError as e:\n",
    "    print(f'Could not find stack from provided stack ID: {cfn_stack_id}')\n",
    "except ClientError as e:\n",
    "    raise(e)\n",
    "    \n",
    "try:\n",
    "    response = secrets_manager.get_secret_value(SecretId=secret_name)\n",
    "    secret_key = response['SecretString']\n",
    "except ClientError as e:\n",
    "    raise(e)\n",
    "    \n",
    "print(f\"ACCESS: {access_key}\")\n",
    "print(f\"SECRET: {secret_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52e1ff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a8cc0b95-590f-4fa6-8b95-65a58774271f'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_connection_res = flow_conn.createConnection(data={\n",
    "    \"name\": f\"[CMLE][Week2] Base Connection to S3 created by {username}\",\n",
    "    \"auth\": {\n",
    "      \"specName\": \"Access Key\",\n",
    "      \"params\": {\n",
    "        \"s3SecretKey\": secret_key,\n",
    "        \"s3AccessKey\": access_key,\n",
    "        \n",
    "      }\n",
    "    },\n",
    "    \"connectionSpec\": {\n",
    "        \"id\": \"4fce964d-3f37-408f-9778-e597338a21ee\",\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    "}) \n",
    "base_connection_id = base_connection_res[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be68712",
   "metadata": {},
   "source": [
    "With that base connection, we're ready to create the target connection that will tie to our S3 directory: Please replace the bucketName and the path with valid values from your S3 configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abde3f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7092cdbf-23e4-44f1-be45-79ff03c42ce9'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: implement in aepp a way to abstract that\n",
    "target_res = flow_conn.createTargetConnection(\n",
    "    data={\n",
    "        \"name\": f\"[CMLE][Week2] S3 target connection created by {username}\",\n",
    "        \"baseConnectionId\": base_connection_id,\n",
    "        \"params\": {\n",
    "            \"mode\": \"Server-to-server\",\n",
    "            \"compression\": compression_type,\n",
    "            \"datasetFileType\": data_format,\n",
    "            \"bucketName\": s3_bucket_name,\n",
    "            \"path\": s3_prefix\n",
    "        },\n",
    "        \"connectionSpec\": {\n",
    "            \"id\": \"4fce964d-3f37-408f-9778-e597338a21ee\",\n",
    "            \"version\": \"1.0\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "target_connection_id = target_res[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd18a9e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "    \n",
    "If you would like to switch to a different cloud storage, you need to update the `connection_spec_id` variable above to the matching value in the table mentioned earlier in this section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07842c",
   "metadata": {},
   "source": [
    "## 4.3 Creating the Data Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58199ff",
   "metadata": {},
   "source": [
    "Now that we have the source and target connections setup, we can construct the data flow. A data flow is the \"recipe\" that describes where the data comes from and where it should end up. We can also specify how often checks happen to find new data, but it cannot be lower than 3 hours currently for platform stability reasons. A data flow is tied to a flow spec ID which contains the instructions for transfering data in an optimized way between a source and destination.\n",
    "\n",
    "For reference, here is a list of all the flow specs available for the most popular cloud storage accounts (these IDs are global across every single customer account and sandbox):\n",
    "\n",
    "| Cloud Storage Type    | Flow Spec ID                         |\n",
    "|-----------------------|--------------------------------------|\n",
    "| Amazon S3             | 269ba276-16fc-47db-92b0-c1049a3c131f |\n",
    "| Azure Blob Storage    | 95bd8965-fc8a-4119-b9c3-944c2c2df6d2 |\n",
    "| Azure Data Lake       | 17be2013-2549-41ce-96e7-a70363bec293 |\n",
    "| Data Landing Zone     | cd2fc47e-e838-4f38-a581-8fff2f99b63a |\n",
    "| Google Cloud Storage  | 585c15c4-6cbf-4126-8f87-e26bff78b657 |\n",
    "| SFTP                  | 354d6aad-4754-46e4-a576-1b384561c440 |\n",
    "\n",
    "In order to execute the data flow, There are two options available to you:\n",
    "- If you do not want to wait you can do a **adhoc run** to execute it instantly in Section 4.4.\n",
    "- Either **wait until it gets scheduled**. We selected to have it run every 3 hours, so you may need to wait up to 3 hours.\n",
    "\n",
    "We have selected the first option by default, if you would select the second option, please change the boolean on_schedule in below cell to True, skip the step for triggering adhoc run located the first cell in Section 4.4, wait up to 3 hours and execute the cells after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f10caed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85ee6381-6c81-4cf7-bdba-097edc8f4bd6'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "on_schedule = False\n",
    "if on_schedule:\n",
    "    schedule_params = {\n",
    "        \"interval\": 3,\n",
    "        \"timeUnit\": \"hour\",\n",
    "        \"startTime\": int(time.time())\n",
    "    }\n",
    "else:\n",
    "    schedule_params = {\n",
    "        \"interval\": 1,\n",
    "        \"timeUnit\": \"day\",\n",
    "        \"startTime\": int(time.time() + 60*60*24*365)\n",
    "    }\n",
    "\n",
    "\n",
    "flow_spec_id = \"269ba276-16fc-47db-92b0-c1049a3c131f\"\n",
    "flow_obj = {\n",
    "    \"name\": f\"[CMLE][Week2] Flow for Featurized Dataset to S3 created by {username}\",\n",
    "    \"flowSpec\": {\n",
    "        \"id\": flow_spec_id,\n",
    "        \"version\": \"1.0\"\n",
    "    },\n",
    "    \"sourceConnectionIds\": [\n",
    "        source_connection_id\n",
    "    ],\n",
    "    \"targetConnectionIds\": [\n",
    "        target_connection_id\n",
    "    ],\n",
    "    \"transformations\": [],\n",
    "    \"scheduleParams\": schedule_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ec618-9240-44eb-b047-6491a30ce05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_res = flow_conn.createFlow(\n",
    "    obj = flow_obj,\n",
    "    flow_spec_id = flow_spec_id\n",
    ")\n",
    "dataflow_id = flow_res[\"id\"]\n",
    "dataflow_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9dc178",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "\n",
    "If you would like to switch to a different cloud storage, you need to update the `flow_spec_id` variable above to the matching value in the table mentioned earlier in this section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff24ad",
   "metadata": {},
   "source": [
    "After you create the data flow, you should be able to see it in the UI to monitor executions, runtimes and its overall lifecycle. You can get the link below and should be able to see it in the UI as shown in the screenshot as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20a9828b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Flow created as ID 85ee6381-6c81-4cf7-bdba-097edc8f4bd6 available under https://experience.adobe.com/#/@aamds/sname:cmle/platform/destination/browse/85ee6381-6c81-4cf7-bdba-097edc8f4bd6\n"
     ]
    }
   ],
   "source": [
    "dataflow_link = get_ui_link(tenant_id, \"destination/browse\", dataflow_id)\n",
    "print(f\"Data Flow created as ID {dataflow_id} available under {dataflow_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66a686",
   "metadata": {},
   "source": [
    "![Dataflow](../media/CMLE-Notebooks-Week2-Dataflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1bd09",
   "metadata": {},
   "source": [
    "## 4.4 Executing the Data Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ca293",
   "metadata": {},
   "source": [
    "At this point we've just created our Data Flow, but it has not executed yet. Please follow the instructions for the option you selected in Section 4.3 :\n",
    "- If you do not want to wait you can do a **adhoc run** to execute it instantly.\n",
    "- Either **wait until it gets scheduled**. We selected to have it run every 3 hours, so you may need to wait up to 3 hours.\n",
    "\n",
    "In the cell below we're showing how to do the first option to trigger a adhoc run, if you selected the second option, you can skip the cell below and will need to wait up to 3 hours to execute the cells after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff4e79",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Please wait at least 10 minutes after creating the dataflow before triggering the next cell, otherwise the job might not execute at all.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d71e029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'destinations': [{'datasets': [{'id': '642d912512f86b1c07ef5650',\n",
       "     'statusURL': 'https://platform.adobe.io/data/foundation/flowservice/runs/e4b252c5-607c-4038-a59c-5e71642abe2d',\n",
       "     'flowId': '85ee6381-6c81-4cf7-bdba-097edc8f4bd6'}]}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use new functionality in aepp when it is released\n",
    "from aepp import connector\n",
    "\n",
    "connector = connector.AdobeRequest(\n",
    "  config_object=aepp.config.config_object,\n",
    "  header=aepp.config.header,\n",
    "  loggingEnabled=False,\n",
    "  logger=None,\n",
    ")\n",
    "\n",
    "endpoint = aepp.config.endpoints[\"global\"] + \"/data/core/activation/disflowprovider/adhocrun\"\n",
    "\n",
    "payload = {\n",
    "    \"activationInfo\": {\n",
    "        \"destinations\": [\n",
    "            {\n",
    "                \"flowId\": dataflow_id, \n",
    "                \"datasets\": [\n",
    "                    {\"id\": created_dataset_id}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "connector.header.update({\"Accept\":\"application/vnd.adobe.adhoc.dataset.activation+json; version=1\"})\n",
    "activation_res = connector.postData(endpoint=endpoint, data=payload)\n",
    "activation_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a78b37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "\n",
    "If you see an error such as `Invalid parameter: Flow for id 93790efa-645b-4400-8afe-b6f135734656 is incorrect. Error is [Adhoc run can not be executed for Flow spec=cd2fc47e-e838-4f38-a581-8fff2f99b63a.`. it means your cloud storage is not yet whitelisted for exporting datasets. Please reach out to your Adobe contact to have it enabled.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d182b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "\n",
    "If you see an error such as `Invalid parameter: Following order ID(s) are not ready for dataset export, please wait for 10 minutes and retry.`. it means you need to wait a few minutes and retry again.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033dee8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> \n",
    "\n",
    "If you get a message saying a run already exists, it means that either this dataset has been exported already based on the schedule, or that you've already done an adhoc export before.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e36552",
   "metadata": {},
   "source": [
    "Now we can check the execution of our Data Flow to make sure it actually executes. You can run the following cell until you can see the run appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "124fe9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID e4b252c5-607c-4038-a59c-5e71642abe2d completed with: duration=17.296 secs; size=2.652714729309082 MB; num_rows=89921; num_files=1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# TODO: handle that more gracefully in aepp\n",
    "finished = False\n",
    "while not finished:\n",
    "    try:\n",
    "        runs = flow_conn.getRuns(prop=f\"flowId=={dataflow_id}\")\n",
    "        for run in runs:\n",
    "            run_id = run[\"id\"]\n",
    "            run_started_at = run[\"metrics\"][\"durationSummary\"][\"startedAtUTC\"]\n",
    "            run_ended_at = run[\"metrics\"][\"durationSummary\"][\"completedAtUTC\"]\n",
    "            run_duration_secs = (run_ended_at - run_started_at) / 1000\n",
    "            run_size_mb = run[\"metrics\"][\"sizeSummary\"][\"outputBytes\"] / 1024. / 1024.\n",
    "            run_num_rows = run[\"metrics\"][\"recordSummary\"][\"outputRecordCount\"]\n",
    "            run_num_files = run[\"metrics\"][\"fileSummary\"][\"outputFileCount\"]\n",
    "            print(f\"Run ID {run_id} completed with: duration={run_duration_secs} secs; size={run_size_mb} MB; num_rows={run_num_rows}; num_files={run_num_files}\")\n",
    "        finished = True\n",
    "    except Exception as e:\n",
    "        print(f\"No runs completed yet for flow {dataflow_id}\")\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fde872",
   "metadata": {},
   "source": [
    "## 4.5 Saving the featurized dataset to the configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe62d6",
   "metadata": {},
   "source": [
    "Now that we got everything working, we just need to save the `created_dataset_id` variable in the original configuration file, so we can refer to it in the following weekly assignments. To do that, execute the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b41c35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"Platform\", \"featurized_dataset_id\", created_dataset_id)\n",
    "\n",
    "with open(config_path, \"w\") as configfile:\n",
    "    config.write(configfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
