{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "631a39f1-9eb5-4f9a-80a6-6b0bb266e45b"
   },
   "source": [
    "# Scope of Notebook\n",
    "\n",
    "This notebook allows you to plug in your featuried dataset from the previous week into an ml model, in this notebook we will use Watsonx AutoAI tool which automates various steps of machine learning model building process by automating data preparion, feature engineering, model selection and hyperparameter optimization. AutoAI operates by analyzing data, selecting most suitable algorithms and then generating multiple model pipelines which it evaluates and ranks based on the performance metrics like accuracy and precission. In the end AutoAI will recommend the best model based on the scoring parameters selected however you are free to chose whichiever model you believe is suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2831ae16a9724df1803258680bb78c5b"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This notebook requires some configuration data to properly authenticate to your Adobe Experience Platform instance. You should be able to find all the values required above by following the Setup section of the watsonx/README.\n",
    "\n",
    "The next cell will be looking for your configuration file to fetch the values used throughout this notebook. See more details in the Setup section of the watsonx/README to understand how to create your configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1d23827dbe69493a80c97c3da1444a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: project-lib in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (2.0.9)\r\n",
      "Requirement already satisfied: requests>=2.18.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from project-lib) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.18.4->project-lib) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.18.4->project-lib) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.18.4->project-lib) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.18.4->project-lib) (2024.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install project-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7bfa49ab8da24baa8c20b3bd76792fbd"
   },
   "outputs": [],
   "source": [
    "from project_lib import Project\n",
    "from configparser import ConfigParser\n",
    "import io\n",
    "\n",
    "project = Project.access()\n",
    "config_file = project.get_file('config.ini')\n",
    "\n",
    "config = ConfigParser()\n",
    "config.read_string(config_file.read().decode('utf-8'))\n",
    "\n",
    "ims_org_id = config.get(\"Platform\", \"ims_org_id\")\n",
    "sandbox_name = config.get(\"Platform\", \"sandbox_name\")\n",
    "environment = config.get(\"Platform\", \"environment\")\n",
    "client_id = config.get(\"Authentication\", \"client_id\")\n",
    "client_secret = config.get(\"Authentication\", \"client_secret\")\n",
    "scopes = config.get(\"Authentication\", \"scopes\")\n",
    "dataset_id = config.get(\"Platform\", \"dataset_id\")\n",
    "featurized_dataset_id = config.get(\"Platform\", \"featurized_dataset_id\")\n",
    "export_path = config.get(\"Cloud\", \"export_path\")\n",
    "import_path = config.get(\"Cloud\", \"import_path\")\n",
    "data_format = config.get(\"Cloud\", \"data_format\")\n",
    "compression_type = config.get(\"Cloud\", \"compression_type\")\n",
    "model_name = config.get(\"Cloud\", \"model_name\")\n",
    "\n",
    "watson_username = config.get(\"Watsonx\", \"watson_username\")\n",
    "watson_apikey = config.get(\"Watsonx\", \"watson_apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60168ce3c27149f59dc9ef84a18be275"
   },
   "source": [
    "Now lets init the APIClient in order to be able to interact with the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2dddc758d151437c8930dae2c5fe1241"
   },
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"instance_id\": \"openshift\",\n",
    "    \"version\": \"4.8\",\n",
    "    \"url\": \"https://cpd-cpd-instance.apps.p712zf6h.eastus2.aroapp.io\",\n",
    "    \"username\": watson_username,\n",
    "    \"apikey\": watson_apikey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "63deada7aa6f46aea2be32151c4b2ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: 506b7b7a-ecf6-454f-8931-6d1aab37044f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "\n",
    "project_id = project.get_metadata()['metadata']['guid']\n",
    "print(\"Project ID:\", project_id)    \n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "client.set.default_project(project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7209b036f33543bf9caebc4bf30700b5"
   },
   "source": [
    "To ensure uniqueness of resources created as part of this notebook, we are using your system provisioned username to include in each of the resource titles to avoid conflicts, \n",
    "it is recommended to supply a more readable one so you could easily identify resources in AEP created by this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "d225aab87fee400fbe73cd88a688a2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: mndymuqvx34peqwqz-ydi68gcdn1kj9ugzqs-towtum\n",
      "Unique ID: mndymuqvx34peqwqz_ydi68gcdn1kj9ugzqs_towtum\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "username=watson_username # supply your custom one ex: foo@bar.com\n",
    "unique_id = s = re.sub(\"[^0-9a-zA-Z]+\", \"_\", watson_username)\n",
    "\n",
    "print(f\"Username: {username}\")\n",
    "print(f\"Unique ID: {unique_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31928c5772814e67a73b38553e1bf0a2"
   },
   "source": [
    "Before we run anything, make sure to install the following required libraries for this notebook. \n",
    "They are all publicly available libraries and the latest version should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ec5419100acd442e96cffd313503b616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aepp in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (0.3.4.post2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aepp) (1.5.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aepp) (2.31.0)\n",
      "Requirement already satisfied: PyJWT in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aepp) (2.4.0)\n",
      "Requirement already satisfied: pathlib2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aepp) (2.3.7.post1)\n",
      "Requirement already satisfied: tenacity in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aepp) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas->aepp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas->aepp) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas->aepp) (1.23.5)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pathlib2->aepp) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=3.3.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from PyJWT[crypto]->aepp) (42.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->aepp) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->aepp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->aepp) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->aepp) (2024.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from cryptography>=3.3.1->PyJWT[crypto]->aepp) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3.1->PyJWT[crypto]->aepp) (2.21)\n",
      "Requirement already satisfied: adlfs in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (2024.4.1)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (1.30.1)\n",
      "Requirement already satisfied: azure-datalake-store<0.1,>=0.0.46 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (0.0.53)\n",
      "Requirement already satisfied: azure-identity in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (1.16.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.12.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (12.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.12.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp>=3.7.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from adlfs) (3.9.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp>=3.7.0->adlfs) (4.0.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.1->adlfs) (4.11.0)\n",
      "Requirement already satisfied: cffi in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.15.1)\n",
      "Requirement already satisfied: msal<2,>=1.16.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.28.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-storage-blob>=12.12.0->adlfs) (42.0.5)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-storage-blob>=12.12.0->adlfs) (0.6.1)\n",
      "Requirement already satisfied: msal-extensions>=0.3.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from azure-identity->adlfs) (1.1.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.21)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2,>=1.16.0->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from msal-extensions>=0.3.0->azure-identity->adlfs) (23.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from msal-extensions>=0.3.0->azure-identity->adlfs) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.1->adlfs) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.1->adlfs) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.1->adlfs) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.23.1->adlfs) (2024.2.2)\n",
      "Requirement already satisfied: s3fs in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (2024.3.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from s3fs) (2.12.3)\n",
      "Requirement already satisfied: fsspec==2024.3.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from s3fs) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from s3fs) (3.9.3)\n",
      "Requirement already satisfied: botocore<1.34.70,>=1.34.41 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.34.69)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.14.1)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (0.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from botocore<1.34.70,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from botocore<1.34.70,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from botocore<1.34.70,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.26.18)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.70,>=1.34.41->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.16.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (2024.3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pyarrow) (1.23.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install aepp\n",
    "!pip install adlfs\n",
    "!pip install s3fs\n",
    "!pip install fsspec\n",
    "!pip install pyarrow \n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b851bf7c9be4e58a0762d359263b517"
   },
   "source": [
    "Before any calls can take place, we need to configure the library and setup authentication credentials. For this you'll need the following piece of information. For information about how you can get these, please refer to the Setup section of the Readme:\n",
    "\n",
    "* Client ID\n",
    "* Client secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fedabd6562874f619c27102b4abc9f8d"
   },
   "outputs": [],
   "source": [
    "import aepp\n",
    "\n",
    "aepp.configure(\n",
    "  environment=environment,\n",
    "  sandbox=sandbox_name,\n",
    "  org_id=ims_org_id,\n",
    "  secret=client_secret,\n",
    "  scopes=scopes,\n",
    "  client_id=client_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51adcfca8eba43e0837d59dfd2a11e69"
   },
   "source": [
    "\n",
    "# 1. Running a model on AEP data\n",
    "\n",
    "In the previous week we generated our featurized data in the Data Landing Zone under the dlz-destination container. We can now read it so we can use it to train our ML model. Because this data can be pretty big, we want to first read it via a Spark dataframe, so we can then use a sample of it for training.\n",
    "\n",
    "The featurized data exported into the Data Landing Zone is under the format `cmle/egress`/`DATASETID`/exportTime=`EXPORTTIME`. We know the dataset ID which is in your config under featurized_dataset_id so we're just missing the export time so we know what to read. To get that we can simply list files in the DLZ and find what the value is. The first step is to retrieve the credentials for the DLZ related to the destination container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "670e7e772d15492e87755354db427750"
   },
   "outputs": [],
   "source": [
    "from aepp import flowservice\n",
    "\n",
    "flow_conn = flowservice.FlowService()\n",
    "credentials = flow_conn.getLandingZoneCredential(dlz_type='dlz_destination')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "222d26f328de40b58d4ed88f05179ae4"
   },
   "source": [
    "Now we use some Python libraries to authenticate and issue listing commands so we can get the paths and extract the time from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1e4c9976701647d7a666a3f9c1fe2a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using featurized data export time of 20240506204134\n"
     ]
    }
   ],
   "source": [
    "import fsspec\n",
    "from fsspec import AbstractFileSystem\n",
    "\n",
    "def getDLZFSPath(credentials: dict):\n",
    "    if 'dlzProvider' in credentials.keys() and ['Amazon', 's3'] in credentials['dlzProvider']:\n",
    "        aws_credentials = {\n",
    "            'key' : credentials['credentials']['awsAccessKeyId'],\n",
    "            'secret' : credentials['credentials']['awsSecretAccessKey'],\n",
    "            'token' : credentials['credentials']['awsSessionToken']\n",
    "        }\n",
    "        return fsspec.filesystem('s3', **aws_credentials), credentials['dlzPath']['bucketName']\n",
    "    else:\n",
    "        abs_credentials = {\n",
    "            'account_name' : credentials['storageAccountName'],\n",
    "            'sas_token' : credentials['SASToken']\n",
    "        }\n",
    "        return fsspec.filesystem('abfss', **abs_credentials), credentials['containerName']\n",
    "    \n",
    "def getDLZDataPath(credentials):\n",
    "    if 'dlzProvider' in credentials.keys() and ['Amazon', 's3'] in credentials['dlzProvider']:\n",
    "        aws_buket = credentials['dlzPath']['bucketName']\n",
    "        dlz_folder = credentials['dlzPath']['dlzFolder']\n",
    "        return f\"s3a://${aws_buket}/{dlz_folder}/\"\n",
    "    else:\n",
    "        dlz_storage_account = credentials['storageAccountName']\n",
    "        dlz_container = credentials['containerName']\n",
    "        return f\"abfss://{dlz_container}@{dlz_storage_account}.dfs.core.windows.net/\"\n",
    "\n",
    "\n",
    "def get_export_time(fs: AbstractFileSystem, container_name: str, base_path: str, dataset_id: str):\n",
    "  featurized_data_base_path = f\"{container_name}/{base_path}/{dataset_id}\"\n",
    "  featurized_data_export_paths = fs.ls(featurized_data_base_path)\n",
    "  \n",
    "  if len(featurized_data_export_paths) == 0:\n",
    "    raise Exception(f\"Found no exports for featurized data from dataset ID {dataset_id} under path {featurized_data_base_path}\")\n",
    "  elif len(featurized_data_export_paths) > 1:\n",
    "    print(f\"Found {len(featurized_data_export_paths)} exports from dataset dataset ID {dataset_id} under path {featurized_data_base_path}, using most recent one\")\n",
    "  \n",
    "  featurized_data_export_path = featurized_data_export_paths[-1]\n",
    "  featurized_data_export_time = featurized_data_export_path.strip().split(\"/\")[-1].split(\"=\")[-1]\n",
    "  return featurized_data_export_time\n",
    "\n",
    "\n",
    "fs, container = getDLZFSPath(credentials)\n",
    "\n",
    "\n",
    "export_time = get_export_time(fs, container, export_path, featurized_dataset_id)\n",
    "print(f\"Using featurized data export time of {export_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c04783d9748242f3b4a0a5b9a67cd8aa"
   },
   "source": [
    "Now we will pull data from from the DLZ and store them locally as assets the following helper functions will help us pull partitioned data so we could feed it into AutoAI later.\n",
    "at the time ow writing this notebook AutoAI supported only CSV and XLSX format, thus we will transform parquet type to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e917e4f9004a41518e4fe505b4d1828f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'file_name': 'dlz_exported_66018d8312377d2c68545bac_data_merged.csv',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'asset_id': '3633fd31-621f-4c64-9004-9806dc7e1604'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = f\"{container}/{export_path}/{featurized_dataset_id}/exportTime={export_time}/\"\n",
    "\n",
    "EXPORTED_FILENAME = f\"dlz_exported_{featurized_dataset_id}_data_merged.csv\"\n",
    "\n",
    "dfs = []\n",
    "for index, file_name in enumerate(fs.ls(data_path)):\n",
    "      if file_name.endswith('.parquet'):\n",
    "        with fs.open(file_name) as parquet_file:\n",
    "            dfs.append(pd.read_parquet(parquet_file))\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "\n",
    "print(combined_df['userId'].nunique())\n",
    "\n",
    "project.save_data(f\"{EXPORTED_FILENAME}\", combined_df.to_csv(index=False))                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b37edc70b7844e7da813eb49f87461e4"
   },
   "source": [
    "Create DataConnections for the above, and confirm data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "b45da2e4a2dc456b8eb1bb46bb494296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset ID: 3633fd31-621f-4c64-9004-9806dc7e1604\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399624 entries, 0 to 399623\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   userId                             399624 non-null  object \n",
      " 1   eventType                          399624 non-null  object \n",
      " 2   timestamp                          399624 non-null  object \n",
      " 3   subscriptionOccurred               399624 non-null  int64  \n",
      " 4   emailsReceived                     399624 non-null  int64  \n",
      " 5   emailsOpened                       399624 non-null  int64  \n",
      " 6   emailsClicked                      399624 non-null  int64  \n",
      " 7   productsViewed                     399624 non-null  int64  \n",
      " 8   propositionInteracts               399624 non-null  int64  \n",
      " 9   propositionDismissed               399624 non-null  int64  \n",
      " 10  webLinkClicks                      399624 non-null  int64  \n",
      " 11  minutes_since_emailSent            378680 non-null  float64\n",
      " 12  minutes_since_emailOpened          221402 non-null  float64\n",
      " 13  minutes_since_emailClick           87425 non-null   float64\n",
      " 14  minutes_since_productView          49526 non-null   float64\n",
      " 15  minutes_since_propositionInteract  4678 non-null    float64\n",
      " 16  minutes_since_propositionDismiss   0 non-null       float64\n",
      " 17  minutes_since_linkClick            53362 non-null   float64\n",
      " 18  random_row_number_for_user         399624 non-null  int64  \n",
      "dtypes: float64(7), int64(9), object(3)\n",
      "memory usage: 57.9+ MB\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.helpers import DataConnection\n",
    "\n",
    "# Find the asset by name\n",
    "asset_id = None\n",
    "for asset in project.get_assets():\n",
    "    if asset['name']== EXPORTED_FILENAME:\n",
    "        asset_id = asset['asset_id']\n",
    "        break\n",
    "\n",
    "if asset_id:\n",
    "    print(\"Asset ID:\", asset_id)\n",
    "else:\n",
    "    print(\"File not found.\")\n",
    "    \n",
    "    \n",
    "trainig_data_connection = DataConnection(data_asset_id = asset_id)\n",
    "\n",
    "trainig_data_connection.read().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3410bc4a60b746ba92e55e73eaf47dad"
   },
   "source": [
    "# 2. Initializing AutoAI\n",
    "\n",
    "Lets now create an instance of AutoAI.\n",
    "We will select several out of the box classification algorithms which comes as part of AutoAI, specify list of features we are interested in as well as label we are trying to predict and lastly chose the scoring.\n",
    "\n",
    "as part of: `train_sample_columns_index_list` we will list column indexes we are interested in (label is also listed):\n",
    "\n",
    "0   userId                            \n",
    "1   eventType                         \n",
    "2   timestamp                         \n",
    "*3   subscriptionOccurred*              \n",
    "*4   emailsReceived*                    \n",
    "*5   emailsOpened*                      \n",
    "*6   emailsClicked*                     \n",
    "*7   productsViewed*                    \n",
    "*8   propositionInteracts*              \n",
    "*9   propositionDismissed*              \n",
    "*10  webLinkClicks*                     \n",
    "*11  minutes_since_emailSent*           \n",
    "*12  minutes_since_emailOpened*         \n",
    "*13  minutes_since_emailClick*          \n",
    "*14  minutes_since_productView*         \n",
    "*15  minutes_since_propositionInteract* \n",
    "*16  minutes_since_propositionDismiss*  \n",
    "17  minutes_since_linkClick           \n",
    "18  random_row_number_for_user        \n",
    "\n",
    "as part of: `include_only_estimators` - will list AutoAI built in/supported classifiers:\n",
    "\n",
    "'RandomForestClassifierEstimator', 'DecisionTreeClassifierEstimator', 'LogisticRegressionEstimator', 'ExtraTreesClassifierEstimator', 'XGBClassifierEstimator', \n",
    "'SnapDecisionTreeClassifierEstimator', 'SnapRandomForestClassifierEstimator', 'SnapLogisticRegressionEstimator', 'SnapSVMClassifierEstimator', 'GradientBoostingClassifierEstimator'\n",
    "\n",
    "we will select for `scoring` : 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "f747b83547784fc88c98b95b3f3fba1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job f1027639-a3e9-4be6-83b0-96d9b6c84118 completed: 100%|████████| [15:11<00:00,  9.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from ibm_watsonx_ai.experiment import AutoAI\n",
    "experiment = AutoAI(wml_credentials, project_id=project_id)\n",
    "\n",
    "pipeline_optimizer = experiment.optimizer(\n",
    "    name=\"Cloud ML Watson (merged csv)\",\n",
    "    prediction_type='binary',\n",
    "    prediction_column='subscriptionOccurred', # label we are trying to predict\n",
    "    holdout_size=0.15,\n",
    "    scoring='roc_auc',\n",
    "    csv_separator=',',\n",
    "    random_state=33,\n",
    "    max_number_of_estimators=2,\n",
    "    include_only_estimators=['RandomForestClassifierEstimator', 'DecisionTreeClassifierEstimator', 'LogisticRegressionEstimator', 'ExtraTreesClassifierEstimator', 'XGBClassifierEstimator', 'SnapDecisionTreeClassifierEstimator', 'SnapRandomForestClassifierEstimator', 'SnapLogisticRegressionEstimator', 'SnapSVMClassifierEstimator', 'GradientBoostingClassifierEstimator'],\n",
    "    text_processing=False,\n",
    "    train_sample_columns_index_list=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], #features indexes we are interested in\n",
    "    positive_label=1,\n",
    "    drop_duplicates=True,\n",
    "    outliers_columns=[],\n",
    "    include_batched_ensemble_estimators=[],\n",
    "    feature_selector_mode='auto'\n",
    ")\n",
    "\n",
    "run_details = pipeline_optimizer.fit(\n",
    "            training_data_reference=[trainig_data_connection],\n",
    "            background_mode=False)\n",
    "\n",
    "\n",
    "pipeline_optimizer.get_run_status()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7793d7d16f7f4106981e2ae160c041ef"
   },
   "source": [
    "### Once pipeline ran lets ensure what parameters were used for AutoAI run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "13098f7cd585468e87fc0867ddc34e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Cloud ML Watson (merged csv)',\n",
       " 'desc': '',\n",
       " 'prediction_type': 'binary',\n",
       " 'prediction_column': 'subscriptionOccurred',\n",
       " 'prediction_columns': None,\n",
       " 'timestamp_column_name': None,\n",
       " 'scoring': 'roc_auc',\n",
       " 'holdout_size': 0.15,\n",
       " 'max_num_daub_ensembles': 2,\n",
       " 't_shirt_size': 'm',\n",
       " 'train_sample_rows_test_size': None,\n",
       " 'include_only_estimators': [<ClassificationAlgorithms.RF: 'RandomForestClassifier'>,\n",
       "  <ClassificationAlgorithms.DT: 'DecisionTreeClassifier'>,\n",
       "  <ClassificationAlgorithms.LR: 'LogisticRegression'>,\n",
       "  <ClassificationAlgorithms.EX_TREES: 'ExtraTreesClassifier'>,\n",
       "  <ClassificationAlgorithms.XGB: 'XGBClassifier'>,\n",
       "  <ClassificationAlgorithms.SnapDT: 'SnapDecisionTreeClassifier'>,\n",
       "  <ClassificationAlgorithms.SnapRF: 'SnapRandomForestClassifier'>,\n",
       "  <ClassificationAlgorithms.SnapLR: 'SnapLogisticRegression'>,\n",
       "  <ClassificationAlgorithms.SnapSVM: 'SnapSVMClassifier'>,\n",
       "  <ClassificationAlgorithms.GB: 'GradientBoostingClassifier'>],\n",
       " 'include_batched_ensemble_estimators': None,\n",
       " 'backtest_num': None,\n",
       " 'lookback_window': None,\n",
       " 'forecast_window': None,\n",
       " 'backtest_gap_length': None,\n",
       " 'cognito_transform_names': None,\n",
       " 'csv_separator': ',',\n",
       " 'excel_sheet': None,\n",
       " 'encoding': 'utf-8',\n",
       " 'positive_label': 1,\n",
       " 'drop_duplicates': True,\n",
       " 'outliers_columns': [],\n",
       " 'text_processing': False,\n",
       " 'word2vec_feature_number': None,\n",
       " 'daub_give_priority_to_runtime': None,\n",
       " 'text_columns_names': None,\n",
       " 'sampling_type': None,\n",
       " 'sample_size_limit': None,\n",
       " 'sample_rows_limit': None,\n",
       " 'sample_percentage_limit': None,\n",
       " 'number_of_batch_rows': None,\n",
       " 'n_parallel_data_connections': None,\n",
       " 'test_data_csv_separator': ',',\n",
       " 'test_data_excel_sheet': None,\n",
       " 'test_data_encoding': 'utf-8',\n",
       " 'categorical_imputation_strategy': None,\n",
       " 'numerical_imputation_strategy': None,\n",
       " 'numerical_imputation_value': None,\n",
       " 'imputation_threshold': None,\n",
       " 'retrain_on_holdout': True,\n",
       " 'feature_columns': None,\n",
       " 'pipeline_types': None,\n",
       " 'supporting_features_at_forecast': None,\n",
       " 'numerical_columns': None,\n",
       " 'categorical_columns': None,\n",
       " 'confidence_level': None,\n",
       " 'incremental_learning': None,\n",
       " 'early_stop_enabled': None,\n",
       " 'early_stop_window_size': None,\n",
       " 'time_ordered_data': None,\n",
       " 'feature_selector_mode': 'auto',\n",
       " 'run_id': 'f1027639-a3e9-4be6-83b0-96d9b6c84118'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0ee13fa11194fa19d7c4e214e25482a"
   },
   "source": [
    "Lets pull some stats from the algo run, get best pipeline (based on selected scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3e36f58762e64bd4b3f13cf66df63b55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enhancements</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>training_roc_auc_(optimized)</th>\n",
       "      <th>holdout_average_precision</th>\n",
       "      <th>holdout_log_loss</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>holdout_roc_auc</th>\n",
       "      <th>training_balanced_accuracy</th>\n",
       "      <th>training_f1</th>\n",
       "      <th>holdout_precision</th>\n",
       "      <th>training_average_precision</th>\n",
       "      <th>training_log_loss</th>\n",
       "      <th>holdout_recall</th>\n",
       "      <th>training_precision</th>\n",
       "      <th>holdout_accuracy</th>\n",
       "      <th>holdout_balanced_accuracy</th>\n",
       "      <th>training_recall</th>\n",
       "      <th>holdout_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pipeline_6</th>\n",
       "      <td></td>\n",
       "      <td>SnapRandomForestClassifier</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.157380</td>\n",
       "      <td>0.938013</td>\n",
       "      <td>0.973661</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.783847</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.862405</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.861938</td>\n",
       "      <td>0.749800</td>\n",
       "      <td>0.786194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_7</th>\n",
       "      <td>HPO</td>\n",
       "      <td>SnapRandomForestClassifier</td>\n",
       "      <td>0.972468</td>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.157380</td>\n",
       "      <td>0.938013</td>\n",
       "      <td>0.973661</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>0.783847</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.862405</td>\n",
       "      <td>0.152513</td>\n",
       "      <td>0.752369</td>\n",
       "      <td>0.821150</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.861938</td>\n",
       "      <td>0.749800</td>\n",
       "      <td>0.786194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_1</th>\n",
       "      <td></td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.972538</td>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.221596</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.973283</td>\n",
       "      <td>0.915630</td>\n",
       "      <td>0.739743</td>\n",
       "      <td>0.618596</td>\n",
       "      <td>0.855574</td>\n",
       "      <td>0.223885</td>\n",
       "      <td>0.938611</td>\n",
       "      <td>0.611540</td>\n",
       "      <td>0.904049</td>\n",
       "      <td>0.918283</td>\n",
       "      <td>0.936167</td>\n",
       "      <td>0.745721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_2</th>\n",
       "      <td>HPO</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.972538</td>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.221596</td>\n",
       "      <td>0.901250</td>\n",
       "      <td>0.973283</td>\n",
       "      <td>0.915630</td>\n",
       "      <td>0.739743</td>\n",
       "      <td>0.618596</td>\n",
       "      <td>0.855574</td>\n",
       "      <td>0.223885</td>\n",
       "      <td>0.938611</td>\n",
       "      <td>0.611540</td>\n",
       "      <td>0.904049</td>\n",
       "      <td>0.918283</td>\n",
       "      <td>0.936167</td>\n",
       "      <td>0.745721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_8</th>\n",
       "      <td>HPO, FE</td>\n",
       "      <td>SnapRandomForestClassifier</td>\n",
       "      <td>0.971145</td>\n",
       "      <td>0.866939</td>\n",
       "      <td>0.145073</td>\n",
       "      <td>0.937508</td>\n",
       "      <td>0.971802</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0.779790</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.150104</td>\n",
       "      <td>0.755483</td>\n",
       "      <td>0.826404</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.738165</td>\n",
       "      <td>0.793538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_9</th>\n",
       "      <td>HPO, FE, HPO</td>\n",
       "      <td>SnapRandomForestClassifier</td>\n",
       "      <td>0.971145</td>\n",
       "      <td>0.866939</td>\n",
       "      <td>0.145073</td>\n",
       "      <td>0.937508</td>\n",
       "      <td>0.971802</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0.779790</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.150104</td>\n",
       "      <td>0.755483</td>\n",
       "      <td>0.826404</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.738165</td>\n",
       "      <td>0.793538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_10</th>\n",
       "      <td>HPO, FE, HPO, Ensemble</td>\n",
       "      <td>BatchedTreeEnsembleClassifier(SnapRandomForest...</td>\n",
       "      <td>0.971145</td>\n",
       "      <td>0.866939</td>\n",
       "      <td>0.145073</td>\n",
       "      <td>0.937508</td>\n",
       "      <td>0.971802</td>\n",
       "      <td>0.855412</td>\n",
       "      <td>0.779790</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.853281</td>\n",
       "      <td>0.150104</td>\n",
       "      <td>0.755483</td>\n",
       "      <td>0.826404</td>\n",
       "      <td>0.941071</td>\n",
       "      <td>0.864640</td>\n",
       "      <td>0.738165</td>\n",
       "      <td>0.793538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_3</th>\n",
       "      <td>HPO, FE</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>0.858676</td>\n",
       "      <td>0.219277</td>\n",
       "      <td>0.901414</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.912265</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.839282</td>\n",
       "      <td>0.225546</td>\n",
       "      <td>0.929526</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.904010</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.927762</td>\n",
       "      <td>0.743795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_4</th>\n",
       "      <td>HPO, FE, HPO</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>0.858676</td>\n",
       "      <td>0.219277</td>\n",
       "      <td>0.901414</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.912265</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.839282</td>\n",
       "      <td>0.225546</td>\n",
       "      <td>0.929526</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.904010</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.927762</td>\n",
       "      <td>0.743795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pipeline_5</th>\n",
       "      <td>HPO, FE, HPO, Ensemble</td>\n",
       "      <td>BatchedTreeEnsembleClassifier(RandomForestClas...</td>\n",
       "      <td>0.969668</td>\n",
       "      <td>0.858676</td>\n",
       "      <td>0.219277</td>\n",
       "      <td>0.901414</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.912265</td>\n",
       "      <td>0.738317</td>\n",
       "      <td>0.619926</td>\n",
       "      <td>0.839282</td>\n",
       "      <td>0.225546</td>\n",
       "      <td>0.929526</td>\n",
       "      <td>0.613155</td>\n",
       "      <td>0.904010</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.927762</td>\n",
       "      <td>0.743795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Enhancements  \\\n",
       "Pipeline Name                           \n",
       "Pipeline_6                              \n",
       "Pipeline_7                        HPO   \n",
       "Pipeline_1                              \n",
       "Pipeline_2                        HPO   \n",
       "Pipeline_8                    HPO, FE   \n",
       "Pipeline_9               HPO, FE, HPO   \n",
       "Pipeline_10    HPO, FE, HPO, Ensemble   \n",
       "Pipeline_3                    HPO, FE   \n",
       "Pipeline_4               HPO, FE, HPO   \n",
       "Pipeline_5     HPO, FE, HPO, Ensemble   \n",
       "\n",
       "                                                       Estimator  \\\n",
       "Pipeline Name                                                      \n",
       "Pipeline_6                            SnapRandomForestClassifier   \n",
       "Pipeline_7                            SnapRandomForestClassifier   \n",
       "Pipeline_1                                RandomForestClassifier   \n",
       "Pipeline_2                                RandomForestClassifier   \n",
       "Pipeline_8                            SnapRandomForestClassifier   \n",
       "Pipeline_9                            SnapRandomForestClassifier   \n",
       "Pipeline_10    BatchedTreeEnsembleClassifier(SnapRandomForest...   \n",
       "Pipeline_3                                RandomForestClassifier   \n",
       "Pipeline_4                                RandomForestClassifier   \n",
       "Pipeline_5     BatchedTreeEnsembleClassifier(RandomForestClas...   \n",
       "\n",
       "               training_roc_auc_(optimized)  holdout_average_precision  \\\n",
       "Pipeline Name                                                            \n",
       "Pipeline_6                         0.972468                   0.864180   \n",
       "Pipeline_7                         0.972468                   0.864180   \n",
       "Pipeline_1                         0.972538                   0.872363   \n",
       "Pipeline_2                         0.972538                   0.872363   \n",
       "Pipeline_8                         0.971145                   0.866939   \n",
       "Pipeline_9                         0.971145                   0.866939   \n",
       "Pipeline_10                        0.971145                   0.866939   \n",
       "Pipeline_3                         0.969668                   0.858676   \n",
       "Pipeline_4                         0.969668                   0.858676   \n",
       "Pipeline_5                         0.969668                   0.858676   \n",
       "\n",
       "               holdout_log_loss  training_accuracy  holdout_roc_auc  \\\n",
       "Pipeline Name                                                         \n",
       "Pipeline_6             0.157380           0.938013         0.973661   \n",
       "Pipeline_7             0.157380           0.938013         0.973661   \n",
       "Pipeline_1             0.221596           0.901250         0.973283   \n",
       "Pipeline_2             0.221596           0.901250         0.973283   \n",
       "Pipeline_8             0.145073           0.937508         0.971802   \n",
       "Pipeline_9             0.145073           0.937508         0.971802   \n",
       "Pipeline_10            0.145073           0.937508         0.971802   \n",
       "Pipeline_3             0.219277           0.901414         0.971014   \n",
       "Pipeline_4             0.219277           0.901414         0.971014   \n",
       "Pipeline_5             0.219277           0.901414         0.971014   \n",
       "\n",
       "               training_balanced_accuracy  training_f1  holdout_precision  \\\n",
       "Pipeline Name                                                               \n",
       "Pipeline_6                       0.860500     0.783847           0.823204   \n",
       "Pipeline_7                       0.860500     0.783847           0.823204   \n",
       "Pipeline_1                       0.915630     0.739743           0.618596   \n",
       "Pipeline_2                       0.915630     0.739743           0.618596   \n",
       "Pipeline_8                       0.855412     0.779790           0.835630   \n",
       "Pipeline_9                       0.855412     0.779790           0.835630   \n",
       "Pipeline_10                      0.855412     0.779790           0.835630   \n",
       "Pipeline_3                       0.912265     0.738317           0.619926   \n",
       "Pipeline_4                       0.912265     0.738317           0.619926   \n",
       "Pipeline_5                       0.912265     0.738317           0.619926   \n",
       "\n",
       "               training_average_precision  training_log_loss  holdout_recall  \\\n",
       "Pipeline Name                                                                  \n",
       "Pipeline_6                       0.862405           0.152513        0.752369   \n",
       "Pipeline_7                       0.862405           0.152513        0.752369   \n",
       "Pipeline_1                       0.855574           0.223885        0.938611   \n",
       "Pipeline_2                       0.855574           0.223885        0.938611   \n",
       "Pipeline_8                       0.853281           0.150104        0.755483   \n",
       "Pipeline_9                       0.853281           0.150104        0.755483   \n",
       "Pipeline_10                      0.853281           0.150104        0.755483   \n",
       "Pipeline_3                       0.839282           0.225546        0.929526   \n",
       "Pipeline_4                       0.839282           0.225546        0.929526   \n",
       "Pipeline_5                       0.839282           0.225546        0.929526   \n",
       "\n",
       "               training_precision  holdout_accuracy  \\\n",
       "Pipeline Name                                         \n",
       "Pipeline_6               0.821150          0.938659   \n",
       "Pipeline_7               0.821150          0.938659   \n",
       "Pipeline_1               0.611540          0.904049   \n",
       "Pipeline_2               0.611540          0.904049   \n",
       "Pipeline_8               0.826404          0.941071   \n",
       "Pipeline_9               0.826404          0.941071   \n",
       "Pipeline_10              0.826404          0.941071   \n",
       "Pipeline_3               0.613155          0.904010   \n",
       "Pipeline_4               0.613155          0.904010   \n",
       "Pipeline_5               0.613155          0.904010   \n",
       "\n",
       "               holdout_balanced_accuracy  training_recall  holdout_f1  \n",
       "Pipeline Name                                                          \n",
       "Pipeline_6                      0.861938         0.749800    0.786194  \n",
       "Pipeline_7                      0.861938         0.749800    0.786194  \n",
       "Pipeline_1                      0.918283         0.936167    0.745721  \n",
       "Pipeline_2                      0.918283         0.936167    0.745721  \n",
       "Pipeline_8                      0.864640         0.738165    0.793538  \n",
       "Pipeline_9                      0.864640         0.738165    0.793538  \n",
       "Pipeline_10                     0.864640         0.738165    0.793538  \n",
       "Pipeline_3                      0.914518         0.927762    0.743795  \n",
       "Pipeline_4                      0.914518         0.927762    0.743795  \n",
       "Pipeline_5                      0.914518         0.927762    0.743795  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pipeline_optimizer.summary()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7213e61312d744e481c5b7ab6d403de0"
   },
   "source": [
    "lets list feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "241b6455552c41ee88ea3a2ad71df5d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>minutes_since_emailClick</th>\n",
       "      <td>0.3113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes_since_emailOpened</th>\n",
       "      <td>0.1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes_since_linkClick</th>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emailsClicked</th>\n",
       "      <td>0.1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes_since_productView</th>\n",
       "      <td>0.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes_since_emailSent</th>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emailsOpened</th>\n",
       "      <td>0.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emailsReceived</th>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productsViewed</th>\n",
       "      <td>0.0122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webLinkClicks</th>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes_since_propositionInteract</th>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propositionInteracts</th>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propositionDismissed</th>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   features_importance\n",
       "minutes_since_emailClick                        0.3113\n",
       "minutes_since_emailOpened                       0.1422\n",
       "minutes_since_linkClick                         0.1370\n",
       "emailsClicked                                   0.1155\n",
       "minutes_since_productView                       0.1117\n",
       "minutes_since_emailSent                         0.0881\n",
       "emailsOpened                                    0.0447\n",
       "emailsReceived                                  0.0125\n",
       "productsViewed                                  0.0122\n",
       "webLinkClicks                                   0.0092\n",
       "minutes_since_propositionInteract               0.0073\n",
       "propositionInteracts                            0.0063\n",
       "propositionDismissed                            0.0021"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.get_pipeline_details()['features_importance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1104524491b64d0fa702c5f877be76f5"
   },
   "source": [
    "\n",
    "lets see accuracy scores of pipelines on the hold out data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93cbcc03300845a398513dc54a16de63"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "summary.holdout_accuracy.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![holdout_accuracy](images/holdout_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets viasualize confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "07b8248a3d4945018cbb7cd49b54c55d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1245</td>\n",
       "      <td>1908</td>\n",
       "      <td>5797</td>\n",
       "      <td>42451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1908</td>\n",
       "      <td>1245</td>\n",
       "      <td>42451</td>\n",
       "      <td>5797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fn    fp     tn     tp\n",
       "true_class                          \n",
       "0.0         1245  1908   5797  42451\n",
       "1.0         1908  1245  42451   5797"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer.get_pipeline_details()['confusion_matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2c5caa0739340b3b290baf94186307e"
   },
   "source": [
    "### lets pull best pipeline and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bee26a76bfc43d28c1b67ccfcf30ff4"
   },
   "outputs": [],
   "source": [
    "best_pipeline = pipeline_optimizer.get_pipeline()\n",
    "best_pipeline.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best_pipeline](images/best_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1fd6c87343e442189f8891aefb1e71a"
   },
   "source": [
    "# 3. Store best pipeline model in repository for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07aa43a5a09e401cb2604ce232a259c0"
   },
   "source": [
    "we will convert it first to sklean so we could further use it in a spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e53e6a3ec694a9c822de4dd8cccefbe"
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline = pipeline_optimizer.get_pipeline(astype='sklearn')\n",
    "\n",
    "sklearn_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn_pipeline](images/sklearn_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d624daa3441464ba02499003df2e660"
   },
   "source": [
    "lets push pipeline in repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "a31a38cf971648578352b3e36a975bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model UID: a9ed5637-f4cf-4446-abcd-6510344762ba\n"
     ]
    }
   ],
   "source": [
    "software_spec_uid = client.software_specifications.get_id_by_name(\"runtime-23.1-py3.10\")\n",
    "software_spec_uid\n",
    "\n",
    "# Define metadata for storing the model\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"CMLE Watson AutoAI Model\",\n",
    "    client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.1',\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "# Store the model in WML repository\n",
    "stored_model_details = client.repository.store_model(\n",
    "    model=sklearn_pipeline, \n",
    "    meta_props=metadata\n",
    ")\n",
    "\n",
    "model_uid = client.repository.get_model_id(stored_model_details)\n",
    "print(\"Model UID:\", model_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9bd7a7327f84aa4834294b71bc60c5d"
   },
   "outputs": [],
   "source": [
    "Now that we got everything working, we just need to save the model_id variable in the original configuration file, so we can refer to it in the following weekly assignments. To do that, execute the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "44ffef1cd79842ad80653a2cc25aeffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'config.ini',\n",
       " 'message': 'File saved to project storage.',\n",
       " 'asset_id': '3b0346fe-24e6-42cf-9f33-38d3b9bc87a7'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.set(\"Watsonx\", \"model_id\", model_uid)\n",
    "config_string = io.StringIO()\n",
    "config.write(config_string)\n",
    "project.save_data(file_name=\"config.ini\", data=config_string.getvalue(), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b06fa451c4844ed2a428790e7d0ae81c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
