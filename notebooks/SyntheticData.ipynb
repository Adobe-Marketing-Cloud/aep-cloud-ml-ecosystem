{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook generates sample data that can be used to illustrate the Cloud ML Ecosystem workflow for using AEP Data for machine learning use cases with external ML tools and platforms. We will generate sample data with the following steps:\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [1. Create Experience Event schema and dataset](#1-create-experience-event-schema-and-dataset)\n",
    "- [2. Statistical simulation of Experience Events](#2-statistical-simulation-of-experience-events)\n",
    "- [3. Ingest sythetic data into AEP dataset](#3-ingest-sythetic-data-into-aep-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setup\n",
    "\n",
    "Before we run anything, make sure to install the following required libraries for this notebook. They are all publicly available libraries and the latest version should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mmh3\n",
    "%pip install rstr\n",
    "%pip install aepp\n",
    "%pip install pygresql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires some configuration data to properly authenticate to your Adobe Experience Platform instance. You should be able to find all the values required above by following the Setup section of the **README**.\n",
    "\n",
    "The next cell will be looking for your configuration file under your **ADOBE_HOME** path to fetch the values used throughout this notebook. See more details in the Setup section of the **README** to understand how to create your configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "import aepp\n",
    "\n",
    "os.environ[\"ADOBE_HOME\"] = os.path.dirname(os.getcwd())\n",
    "\n",
    "if \"ADOBE_HOME\" not in os.environ:\n",
    "    raise Exception(\"ADOBE_HOME environment variable needs to be set.\")\n",
    "\n",
    "config = ConfigParser()\n",
    "config_file = \"cmle_gov_config.ini\"\n",
    "config_path = os.path.join(os.environ[\"ADOBE_HOME\"], \"conf\", config_file)\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    raise Exception(f\"Looking for configuration under {config_path} but config not found, please verify path\")\n",
    "\n",
    "config.read(config_path)\n",
    "\n",
    "aepp.configure(\n",
    "  org_id=config.get(\"Platform\", \"ims_org_id\"),\n",
    "  tech_id=config.get(\"Authentication\", \"tech_acct_id\"), \n",
    "  secret=config.get(\"Authentication\", \"client_secret\"),\n",
    "  scopes=config.get(\"Authentication\", \"scopes\"),\n",
    "  client_id=config.get(\"Authentication\", \"client_id\"),\n",
    "  environment=config.get(\"Platform\", \"environment\"),\n",
    "  sandbox=config.get(\"Platform\", \"sandbox_name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure uniqueness of resources created as part of this notebook, we are using your local username to include in each of the resource titles to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "username = os.getlogin()\n",
    "unique_id = s = re.sub(\"[^0-9a-zA-Z]+\", \"_\", username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions that will be used throughout this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ui_link(tenant_id, resource_type, resource_id):\n",
    "    environment = config.get(\"Platform\", \"environment\")\n",
    "    sandbox_name = config.get(\"Platform\", \"sandbox_name\")\n",
    "    if environment == \"prod\":\n",
    "        prefix = f\"https://experience.adobe.com\"\n",
    "    else:\n",
    "        prefix = f\"https://experience-{environment}.adobe.com\"\n",
    "    return f\"{prefix}/#/@{tenant_id}/sname:{sandbox_name}/platform/{resource_type}/{resource_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Experience Event schema and dataset\n",
    "\n",
    "We will now create the schema to support our synthetic data. We need a few fields which will be included in the synthetic event data:\n",
    "- Direct Marketing information\n",
    "- Web details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create connection to XDM Schema Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepp import schema\n",
    "schema_conn = schema.Schema()\n",
    "schema_conn.sandbox\n",
    "tenant_id = schema_conn.getTenantId()\n",
    "tenant_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create User ID field group for Experience Event Schema\n",
    "\n",
    "We need to create a custom field group with a \"userId\" field to go in the experience event schema. Other schema fields will come from standard field field groups we will include when creating the schema.\n",
    "\n",
    "First we'll define some utility functions to gracefully handle cases where the User ID field group has already been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFieldGroupbyTitle(schema_conn: schema.Schema, title: str):\n",
    "    fieldgroups = schema_conn.getFieldGroups()\n",
    "    match = list(filter(lambda d: d['title'] == title, fieldgroups))\n",
    "    if len(match) == 1:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFieldGroupifnotExists(schema_conn: schema.Schema, title: str, data: dict):\n",
    "    existing = getFieldGroupbyTitle(schema_conn, title)\n",
    "    if existing:\n",
    "        print(f\"'{title}' already exists, retrieving existing field group\")\n",
    "        return existing\n",
    "    else:\n",
    "        return schema_conn.createFieldGroup(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the User ID field group (or retrieve the field group ID if it already exists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldgroup_title = f\"[CMLE Synthetic Data] Exp Event User ID (created by {username})\"\n",
    "fieldgroup_data = {\n",
    "  \"type\": \"object\",\n",
    "\t\"title\": fieldgroup_title,\n",
    "\t\"description\": \"This field group is used to identify the user to whom an experience event belongs.\",\n",
    "\t\"allOf\": [{\n",
    "\t\t\"$ref\": \"#/definitions/customFields\"\n",
    "\t}],\n",
    "\t\"meta:containerId\": \"tenant\",\n",
    "\t\"meta:resourceType\": \"mixins\",\n",
    "\t\"meta:xdmType\": \"object\",\n",
    "\t\"definitions\": {\n",
    "      \"customFields\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          f\"_{tenant_id}\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"userId\": {\n",
    "                \"title\": \"User ID\",\n",
    "                \"description\": \"This refers to the user having a propensity towards an outcome.\",\n",
    "                \"type\": \"string\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "\t},\n",
    "\t\"meta:intendedToExtend\": [\"https://ns.adobe.com/xdm/context/experienceevent\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fieldgroup_res = createFieldGroupifnotExists(schema_conn, fieldgroup_title, fieldgroup_data)\n",
    "fieldgroup_id = fieldgroup_res['$id']\n",
    "print(f\"User ID field group ID: {fieldgroup_id}\")\n",
    "\n",
    "# Get link to field group in AEP UI\n",
    "import urllib.parse\n",
    "fieldgroup_link = get_ui_link(tenant_id, \"schema/mixin/browse\", urllib.parse.quote(fieldgroup_id, safe=\"a\"))\n",
    "print(f\"View field group in UI: {fieldgroup_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compose Experience Event schema\n",
    "\n",
    "Now we'll create the experience event schema from our custom field group and the following standard field groups:\n",
    "- Direct Marketing Details\n",
    "- Web Details\n",
    "\n",
    "First we'll define some utility functions to gracefully handle cases where the Experience Event schema has already been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSchemabyTitle(schema_conn: schema.Schema, title: str):\n",
    "    schemas = schema_conn.getSchemas()\n",
    "    # Handle case where no schemas have been created\n",
    "    if 'results' in schemas: \n",
    "        return None\n",
    "    # Filter schemas list for matching title\n",
    "    match = list(filter(lambda d: d['title'] == title, schemas))\n",
    "    # XDM schema titles must be unique, so 'match' will have exactly 1 element if a schema\n",
    "    # with the same title already exists\n",
    "    if len(match) == 1:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEESchemaifnotExists(schema_conn: schema.Schema, title: str, fieldGroups: list[str], description: str = \"\"):\n",
    "    existing = getSchemabyTitle(schema_conn, title)\n",
    "    if existing:\n",
    "        print(f\"'{title}' already exists, retrieving existing schema\")\n",
    "        return existing\n",
    "    else:\n",
    "        return schema_conn.createExperienceEventSchema(\n",
    "            name=title,\n",
    "            fieldGroupIds=fieldGroups,\n",
    "            description=description\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Experience Event schema (or retrieve the ID and Alt ID if the schema already exists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_ee_title = f\"[CMLE Synthetic Data] Experience Event schema (created by {username})\"\n",
    "schema_ee_fgs = [\n",
    "    fieldgroup_id,\n",
    "    \"https://ns.adobe.com/xdm/context/experienceevent-directmarketing\",\n",
    "    \"https://ns.adobe.com/xdm/context/experienceevent-web\"\n",
    "]\n",
    "schema_ee_desc = \"Profile Schema generated by CMLE for synthetic events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_ee_res = createEESchemaifnotExists(\n",
    "    schema_conn=schema_conn,\n",
    "    title=schema_ee_title,\n",
    "    fieldGroups=schema_ee_fgs,\n",
    "    description=schema_ee_desc\n",
    ")\n",
    "schema_ee_id = schema_ee_res['$id']\n",
    "schema_ee_altId = schema_ee_res[\"meta:altId\"]\n",
    "print(f\"EE Schema ID: {schema_ee_id}\")\n",
    "print(f\"EE Schema Alt ID: {schema_ee_altId}\")\n",
    "\n",
    "schema_ee_link = get_ui_link(tenant_id, \"schema/mixin/browse\", urllib.parse.quote(schema_ee_id, safe=\"a\"))\n",
    "print(f\"View EE schema in UI: {schema_ee_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set \"userId\" as the primary ID for the schema with ECID as the namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_type = \"ECID\"\n",
    "identity_desc_data = {\n",
    "    \"@type\": \"xdm:descriptorIdentity\",\n",
    "    \"xdm:sourceSchema\": schema_ee_id,\n",
    "    \"xdm:sourceVersion\": 1,\n",
    "    \"xdm:sourceProperty\": f\"/_{tenant_id}/userId\",\n",
    "    \"xdm:namespace\": identity_type,\n",
    "    \"xdm:property\": \"xdm:id\",\n",
    "    \"xdm:isPrimary\": True\n",
    "  }\n",
    "identity_dsc_ee_res = schema_conn.createDescriptor(\n",
    "    descriptorObj = identity_desc_data\n",
    ")\n",
    "identity_dsc_ee_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable EE schema for Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_ee_res = schema_conn.enableSchemaForRealTime(schema_ee_altId)\n",
    "enable_ee_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Experience Event dataset\n",
    "\n",
    "First, create a connection to the Catalog API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepp import catalog\n",
    "cat_conn = catalog.Catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some utility functions to gracefully handle cases where the Experience Event dataset has alrerady been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetbyName(cat_conn: catalog.Catalog, name: str):\n",
    "    datasets = cat_conn.getDataSets()\n",
    "    match = {k:v for k, v in datasets.items() if v['name'] == name}\n",
    "    if match:\n",
    "        return list(match.keys())[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDatasetifNotExists(cat_conn: catalog.Catalog, name: str, schemaId: str):\n",
    "    existing = getDatasetbyName(cat_conn=cat_conn, name=name)\n",
    "    if existing:\n",
    "        return existing\n",
    "    else:\n",
    "        dataset = cat_conn.createDataSets(name=name, schemaId=schemaId)\n",
    "        return dataset[0].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Experience Event dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ee_name = f\"[CMLE Synthetic Data] Experience Event dataset (created by {username})\"\n",
    "dataset_ee_id = createDatasetifNotExists(cat_conn=cat_conn, name=dataset_ee_name, schemaId=schema_ee_id)\n",
    "print(f\"EE Dataset ID: {dataset_ee_id}\")\n",
    "\n",
    "dataset_ee_link = get_ui_link(tenant_id, \"dataset/browse\", dataset_ee_id)\n",
    "print(f\"View EE Dataset in UI: {dataset_ee_link}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable dataset for Profile\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> After you do this step please go in the UI and click on the link above, if the profile toggle is not enabled please manually toggle the profile on\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_conn.enableDatasetProfile(dataset_ee_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Statistical simulation of Experience Events\n",
    "\n",
    "We will set up a statistical simulation to generate Experience event data that can be used illustrate the end-to-end flow of creating a propensity model to predict subscriptions to a brand's paid service.\n",
    "\n",
    "We will use the standard `web.formFilledOut` event type to represent the subscription conversions that the brand wants to predict, and generate similulated sequences of various types of experience events along with the target subscription conversions that will be used to train a propensity model.\n",
    "\n",
    "## 2.1 Event types and their contribution to propensity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "import mmh3\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some events and dependencies between the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising_events = {\n",
    " \n",
    "    #eventType          : (weeklyAverageOccurrence, propensityDelta, [(field_to_replace, value)], timeInHoursFromDependent)\n",
    "    \"advertising.clicks\": (0.01,                    0.002,            [(\"advertising/clicks/value\", 1.0)], 0.5) , \n",
    "    \"advertising.impressions\": (0.1, 0.001, [(\"advertising/impressions/value\", 1.0)], 0),\n",
    "\n",
    "    \"web.webpagedetails.pageViews\": (0.1, 0.005, [(\"web/webPageDetails/pageViews/value\", 1.0)], 0.1),\n",
    "    \"web.webinteraction.linkClicks\": (0.05, 0.005, [(\"web/webInteraction/linkClicks/value\", 1.0)], 0.1),\n",
    "   \n",
    "    \n",
    "    \"commerce.productViews\": (0.05, 0.005, [(\"commerce/productViews/value\", 1.0)], 0.2),\n",
    "    \"commerce.purchases\": (0.01, 0.1, [(\"commerce/purchases/value\", 1.0)], 1),\n",
    "    \n",
    "    \n",
    "    \"decisioning.propositionDisplay\": (0.05, 0.005, [(\"_experience/decisioning/propositionEventType/display\", 1)], 0.1),\n",
    "    \"decisioning.propositionInteract\": (0.01, 0.1, [(\"_experience/decisioning/propositionEventType/interact\", 1)], 0.05),\n",
    "    \"decisioning.propositionDismiss\": (0.01, -0.2, [(\"_experience/decisioning/propositionEventType/dismiss\", 1)], 0.05),\n",
    "\n",
    "    \n",
    "    \"directMarketing.emailOpened\": (0.2, 0.02, [(\"directMarketing/opens/value\", 1.0)], 24),\n",
    "    \"directMarketing.emailClicked\": (0.05, 0.1, [(\"directMarketing/clicks/value\", 1.0)], 0.5),\n",
    "    \"directMarketing.emailSent\": (0.5, 0.005, [(\"directMarketing/sends/value\", 1.0)], 0),\n",
    "    \n",
    "    \"web.formFilledOut\": (0.0, 0.0, [(\"web/webPageDetails/name\", \"subscriptionForm\")], 0),\n",
    "\n",
    "}\n",
    "\n",
    "event_dependencies = {\n",
    "    \"advertising.impressions\": [\"advertising.clicks\"],\n",
    "    \"directMarketing.emailSent\": [\"directMarketing.emailOpened\"],\n",
    "    \"directMarketing.emailOpened\": [\"directMarketing.emailClicked\"],\n",
    "    \"directMarketing.emailClicked\": [\"web.webpagedetails.pageViews\"],\n",
    "    \"web.webpagedetails.pageViews\": [\"web.webinteraction.linkClicks\", \"commerce.productViews\", \"decisioning.propositionDisplay\"],\n",
    "    \"commerce.productViews\": [\"commerce.purchases\"],\n",
    "    \"decisioning.propositionDisplay\": [\"decisioning.propositionInteract\", \"decisioning.propositionDismiss\"]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions that will be used to implement the event simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime \n",
    "    objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = randrange(int_delta)\n",
    "    return start + timedelta(seconds=random_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data_for_n_users(n_users, first_user):\n",
    "  \n",
    "  N_USERS = n_users\n",
    "  FIRST_USER = first_user\n",
    "  \n",
    "  N_WEEKS = 10\n",
    "  GLOBAL_START_DATE = datetime.now() - timedelta(weeks=12)\n",
    "  GLOBAL_END_DATE = GLOBAL_START_DATE + timedelta(weeks=N_WEEKS)\n",
    "\n",
    "  events = []\n",
    "\n",
    "  for user in range(N_USERS):\n",
    "        user_id = FIRST_USER + user\n",
    "        user_events = []\n",
    "        base_events = {}\n",
    "        for event_type in [\"advertising.impressions\", \"web.webpagedetails.pageViews\", \"directMarketing.emailSent\"]:\n",
    "            n_events = np.random.poisson(advertising_events[event_type][0] * N_WEEKS)\n",
    "            times = []\n",
    "            for _ in range(n_events):\n",
    "                #times.append(random_date(GLOBAL_START_DATE, GLOBAL_END_DATE)\n",
    "                times.append(random_date(GLOBAL_START_DATE, GLOBAL_END_DATE).isoformat())\n",
    "\n",
    "            base_events[event_type] = times\n",
    "\n",
    "        for event_type, dependent_event_types in event_dependencies.items():\n",
    "\n",
    "            if event_type in base_events:\n",
    "                #for each originating event\n",
    "                for event_time in base_events[event_type]:\n",
    "                    #Look for possible later on events\n",
    "                    for dependent_event in dependent_event_types:\n",
    "                                n_events = np.random.poisson(advertising_events[dependent_event][0] * N_WEEKS)\n",
    "                                times = []\n",
    "                                for _ in range(n_events):\n",
    "                                    #times.append(event_time + timedelta(hours = np.random.exponential(advertising_events[dependent_event][3])))\n",
    "                                    new_time = datetime.fromisoformat(event_time) + timedelta(hours = np.random.exponential(advertising_events[dependent_event][3]))\n",
    "                                    times.append(new_time.isoformat())\n",
    "                                base_events[dependent_event] = times\n",
    "\n",
    "\n",
    "        for event_type, times in base_events.items():\n",
    "            for time in times:\n",
    "                user_events.append({\"userId\": user_id, \"eventType\": event_type, \"timestamp\": time})\n",
    "\n",
    "        user_events = sorted(user_events, key = lambda x: (x[\"userId\"], x[\"timestamp\"]))\n",
    "\n",
    "\n",
    "        cumulative_probability = 0.001\n",
    "        subscribed = False\n",
    "        for event in user_events:\n",
    "            cumulative_probability = min(1.0, max(cumulative_probability + advertising_events[event[\"eventType\"]][1], 0))\n",
    "            event[\"subscriptionPropensity\"] = cumulative_probability\n",
    "            if subscribed == False and \"directMarketing\" not in event[\"eventType\"] and \"advertising\" not in event[\"eventType\"]:\n",
    "                subscribed = np.random.binomial(1, cumulative_probability) > 0\n",
    "                if subscribed:\n",
    "                    subscriptiontime = (datetime.fromisoformat(event[\"timestamp\"]) + timedelta(seconds = 60)).isoformat()\n",
    "                    #subscriptiontime = event[\"timestamp\"] + timedelta(seconds = 60)\n",
    "                    user_events.append({\"userId\": user_id, \"eventType\": \"web.formFilledOut\",  \"timestamp\": subscriptiontime})\n",
    "            event[\"subscribed\"] = subscribed\n",
    "        user_events = sorted(user_events, key = lambda x: (x[\"userId\"], x[\"timestamp\"]))\n",
    "\n",
    "        events = events + user_events\n",
    "  return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ecid(ecid_part):\n",
    "    ecid_part_str = str(abs(ecid_part))\n",
    "    if len(ecid_part_str) != 19:\n",
    "        ecid_part_str = \"\".join([str(x) for x in range(\n",
    "            0, 19 - len(ecid_part_str))]) + ecid_part_str\n",
    "    return ecid_part_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ecid(email):\n",
    "    \"\"\"\n",
    "    The ECID must be two valid 19 digit longs concatenated together\n",
    "    \"\"\"\n",
    "    ecidpart1, ecidpart2 = mmh3.hash64(email)\n",
    "    ecid1, ecid2 = (normalize_ecid(ecidpart1), normalize_ecid(ecidpart2))\n",
    "    return ecid1 + ecid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that goes into an email event payload\n",
    "def create_email_event(user_id, event_type, timestamp):\n",
    "  \"\"\"\n",
    "  Combines previous methods to create various type of email events\n",
    "  \"\"\"\n",
    "  \n",
    "  if event_type == \"directMarketing.emailSent\":\n",
    "    directMarketing = {\"emailDelivered\": {\"value\": 1.0}, \n",
    "                       \"sends\": {\"value\": 1.0}, \n",
    "                       \"emailVisitorID\": user_id,\n",
    "                       \"hashedEmail\": ''.join(random.choices(string.ascii_letters + string.digits, k=10)),\n",
    "                       \"messageID\": str(uuid.uuid4()),\n",
    "                      }\n",
    "  elif event_type == \"directMarketing.emailOpened\":\n",
    "    directMarketing = {\"offerOpens\": {\"value\": 1.0}, \n",
    "                     \"opens\": {\"value\": 1.0}, \n",
    "                     \"emailVisitorID\": user_id,\n",
    "                     \"messageID\": str(uuid.uuid4()),\n",
    "                    }\n",
    "  elif event_type == \"directMarketing.emailClicked\":\n",
    "    directMarketing = {\"clicks\": {\"value\": 1.0}, \n",
    "                     \"offerOpens\": {\"value\": 1.0}, \n",
    "                     \"emailVisitorID\": user_id,\n",
    "                     \"messageID\": str(uuid.uuid4()),\n",
    "                    }\n",
    "  return {\n",
    "    \"directMarketing\": directMarketing,\n",
    "    \"web\": None,\n",
    "    \"_id\": str(uuid.uuid4()),\n",
    "    \"eventMergeId\": None,\n",
    "    \"eventType\": event_type,\n",
    "    f\"_{tenant_id}\": {\"userId\":get_ecid(user_id)},\n",
    "    \"producedBy\": \"databricks-synthetic\",\n",
    "    \"timestamp\": timestamp\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that goes into a web event payload \n",
    "def create_web_event(user_id, event_type, timestamp):\n",
    "  \"\"\"\n",
    "  Combines previous methods to creat various type of web events\n",
    "  \"\"\"\n",
    "  url = f\"http://www.{''.join(random.choices(string.ascii_letters + string.digits, k=5))}.com\"\n",
    "  ref_url = f\"http://www.{''.join(random.choices(string.ascii_letters + string.digits, k=5))}.com\"\n",
    "  name = ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "  isHomePage = random.choice([True, False])\n",
    "  server = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "  site_section = ''.join(random.choices(string.ascii_letters, k=2))\n",
    "  view_name = ''.join(random.choices(string.ascii_letters, k=3))\n",
    "  region = ''.join(random.choices(string.ascii_letters + string.digits, k=5))\n",
    "  interaction_type = random.choice([\"download\", \"exit\", \"other\"])\n",
    "  web_referrer = random.choice([\"internal\", \"external\", \"search_engine\", \"email\", \"social\", \"unknown\", \"usenet\", \"typed_bookmarked\"])\n",
    "  base_web = {\"webInteraction\": {\"linkClicks\": {\"value\": 0.0}, \n",
    "                                 \"URL\": url, \n",
    "                                 \"name\": name,\n",
    "                                \"region\": region,\n",
    "                                \"type\": interaction_type},\n",
    "              \"webPageDetails\": {\"pageViews\": {\"value\": 1.0},\n",
    "                                 \"URL\": url,\n",
    "                                 \"isErrorPage\": False,\n",
    "                                 #\"isHomepage\": isHomePage,\n",
    "                                 \"name\": name,\n",
    "                                 \"server\": server,\n",
    "                                 \"siteSection\": site_section,\n",
    "                                 \"viewName\": view_name\n",
    "                                },\n",
    "              \"webReferrer\": {\n",
    "                \"URL\": ref_url,\n",
    "                \"type\": web_referrer\n",
    "              }\n",
    "             }\n",
    "  if event_type in [\"advertising.clicks\", \"commerce.purchases\", \"web.webinteraction.linkClicks\", \"web.formFilledOut\", \n",
    "                   \"decisioning.propositionInteract\", \"decisioning.propositionDismiss\"]:\n",
    "    base_web[\"webInteraction\"][\"linkClicks\"][\"value\"] = 1.0\n",
    "\n",
    "  return {\n",
    "    \"directMarketing\": None,\n",
    "    \"web\": base_web,\n",
    "    \"_id\": str(uuid.uuid4()),\n",
    "    \"eventMergeId\": None,\n",
    "    \"eventType\": event_type,\n",
    "    f\"_{tenant_id}\": {\"userId\":get_ecid(user_id)},\n",
    "    \"producedBy\": \"databricks-synthetic\",\n",
    "    \"timestamp\": timestamp\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def create_xdm_event(user_id, event_type, timestamp):\n",
    "  \"\"\"\n",
    "  The final 'event factory' method that converts an event into an XDM event\n",
    "  \"\"\"\n",
    "  if \"directMarketing\" in event_type:\n",
    "    return create_email_event(user_id, event_type, timestamp)\n",
    "  else: \n",
    "    return create_web_event(user_id, event_type, timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ingest sythetic data into AEP dataset\n",
    "\n",
    "We'll now use the functions defined above to simulate sequences of Experience Events for a number of users, then ingest the simulated event data into the Experience Event dataset we create above.\n",
    "\n",
    "For each batch, we will:\n",
    "1. Initialize a batch to ingest to our Experience Event dataset\n",
    "2. Generate a sequence of simulate events using the `create_data_for_n_users` function\n",
    "3. Format the events into XDM Experience Event payloads using the `create_xdm_event` function\n",
    "4. Add the synthetic data to the batch\n",
    "5. Close the batch\n",
    "\n",
    "First create a connection to the AEP batch ingestion API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepp import ingestion\n",
    "ingest_conn = ingestion.DataIngestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingestSyntheticBatch(\n",
    "        ingest_conn: ingestion.DataIngestion,\n",
    "        n_users: int = 10000,\n",
    "        first_user_id: int = 1,\n",
    "        event_dataset: str = None,\n",
    "        profile_dataset: str = None) -> str:\n",
    "    if not events and not profiles:\n",
    "        raise AttributeError('At least one of \"events\" or \"profiles\" must be True')\n",
    "    if event_dataset:\n",
    "        # Generate batch of synthetic events data\n",
    "\n",
    "        # Initialize batch creation\n",
    "\n",
    "        # Upload data\n",
    "\n",
    "        # Complete the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then repeat the sequences of actions described above to generate and ingest simulated events for the desired number of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/10 with ID 01H9K8K64GDPDP4XEFA7AFQVS1\n",
      "Processing batch 2/10 with ID 01H9K8KSRQPNBDBGDR9W5DYGZB\n",
      "Processing batch 3/10 with ID 01H9K8MQ6JVW1FJFG407C47V2S\n",
      "Processing batch 4/10 with ID 01H9K8NE5Z12K48FNW8YAEC2QM\n",
      "Processing batch 5/10 with ID 01H9K8P1030D5TK7GRRFC0H4CA\n",
      "Processing batch 6/10 with ID 01H9K8PMEJ8763QN5J8AFQVZG5\n",
      "Processing batch 7/10 with ID 01H9K8QE71R9G17KYZTF482MFM\n",
      "Processing batch 8/10 with ID 01H9K8R84H67G0W13ME0W9BK0M\n",
      "Processing batch 9/10 with ID 01H9K8RWWRY19VXEAPSAHHFWP0\n",
      "Processing batch 10/10 with ID 01H9K8SFCASX2QRC2JE08PYEEG\n"
     ]
    }
   ],
   "source": [
    "num_batches = 10\n",
    "batch_size = 10000\n",
    "dataset_id = dataset_ee_id\n",
    "\n",
    "batch_ids = []\n",
    "for batch_index in range(num_batches):\n",
    "  first_user_id_for_batch = batch_index * batch_size\n",
    "  batch_events = create_data_for_n_users(batch_size, first_user_id_for_batch)\n",
    "  batch_data = [create_xdm_event(f\"synthetic-user-{x['userId']}@emailsim.io\", x[\"eventType\"], x[\"timestamp\"]) for x in batch_events]\n",
    "  \n",
    "  # Initialize batch creation\n",
    "  batch_res = ingest_conn.createBatch(\n",
    "    datasetId = dataset_id\n",
    "  )\n",
    "  #print(str(batch_res))\n",
    "  batch_id = batch_res[\"id\"]\n",
    "  print(f\"Processing batch {batch_index + 1}/{num_batches} with ID {batch_id}\")\n",
    "  \n",
    "  # Upload XDM data\n",
    "  file_path = f\"batch-synthetic-{batch_id}\"\n",
    "  ingest_conn.uploadSmallFile(\n",
    "    batchId = batch_id,\n",
    "    datasetId = dataset_id,\n",
    "    filePath = batch_id,\n",
    "    data = batch_data\n",
    "  )\n",
    "  \n",
    "  # Complete the batch\n",
    "  ingest_conn.uploadSmallFileFinish(\n",
    "    batchId = batch_id\n",
    "  )\n",
    "  \n",
    "  # Store the batch ID to check status\n",
    "  batch_ids.append(batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Batches are ingested asynchronously in AEP. It may take some time for all the data generated here to be available in your dataset depending on how your AEP organization has been provisioned. You can check ingestion status for all your batches in [the dataset page of your AEP UI](https://experience.adobe.com/#/@TENANT/sname:SANDBOX/platform/dataset/browse/DATASETID)\n",
    "\n",
    "You can also check the ingestion status from the notebook by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining batches being ingested: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRemaining batches being ingested: \u001b[39m\u001b[39m{\u001b[39;00mnum_incomplete_batches\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m   time\u001b[39m.\u001b[39;49msleep(\u001b[39m30\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from aepp import catalog\n",
    "import time\n",
    "cat_conn = catalog.Catalog()\n",
    "\n",
    "all_ingested = False\n",
    "while not all_ingested:\n",
    "  incomplete_batches = cat_conn.getBatches(\n",
    "    limit=min(100, num_batches),\n",
    "    n_results=num_batches,\n",
    "    output=\"dataframe\",\n",
    "    dataSet=dataset_id,\n",
    "    status=\"staging\"\n",
    "  )\n",
    "  \n",
    "  num_incomplete_batches = len(incomplete_batches)\n",
    "  if num_incomplete_batches == 0:\n",
    "    print(\"All batches have been ingested\")\n",
    "    all_ingested = True\n",
    "  else:\n",
    "    print(f\"Remaining batches being ingested: {num_incomplete_batches}\")\n",
    "    time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
